import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics.pairwise import euclidean_distances
import os
import copy
import umap
import seaborn as sns
import optuna
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.distributions import Normal
from sklearn.metrics import mean_squared_error
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split, GridSearchCV
from tqdm import tqdm


# class NNModel(nn.Module):
#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):
#         super(NNModel, self).__init__()
#
#         self.model = nn.Sequential(
#             nn.Linear(input_size, hidden_size1),
#             nn.BatchNorm1d(hidden_size1),
#             nn.LeakyReLU(),
#             nn.Linear(hidden_size1, hidden_size2),
#             nn.BatchNorm1d(hidden_size2),
#             nn.LeakyReLU(),
#             nn.Linear(hidden_size2, output_size)
#         )
#
#     def forward(self, x):
#         return self.model(x)


class NNModel(nn.Module):
    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):
        super(NNModel, self).__init__()

        self.fc1 = nn.Linear(input_size, hidden_size1)
        self.bn1 = nn.BatchNorm1d(hidden_size1)
        self.relu1 = nn.LeakyReLU()

        self.fc2 = nn.Linear(hidden_size1, hidden_size2)
        self.bn2 = nn.BatchNorm1d(hidden_size2)
        self.relu2 = nn.LeakyReLU()

        self.fc3 = nn.Linear(hidden_size2, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = self.bn1(x)
        x = self.relu1(x)

        x = self.fc2(x)
        x = self.bn2(x)
        x = self.relu2(x)

        x = self.fc3(x)

        return x


df = pd.read_csv("/home/fanqiany/data/fanqiany/APOGEEDR17_GAIAEDR3_noflagfilter.csv")
chemical_abundances = ['FE_H', 'C_FE', 'CI_FE', 'N_FE', 'O_FE', 'MG_FE', 'AL_FE',
                       'SI_FE', 'P_FE', 'S_FE', 'K_FE', 'CA_FE', 'TI_FE', 'TIII_FE',
                       'V_FE', 'CR_FE', 'MN_FE', 'CO_FE', 'NI_FE']

# remove 'ASPCAPFLAG' and 'STARFLAG'
selected_df = df[(df['ASPCAPFLAG'] == 0) & (df['STARFLAG'] == 0)][chemical_abundances]

# remove outliers if exist
z_scores = abs((selected_df - selected_df.mean()) / selected_df.std())
data_no_outliers = selected_df[(z_scores < 3).all(axis=1)]

# standard scale
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data_no_outliers)

# save cleaned dataset
cleaned_df = pd.DataFrame(scaled_data, columns=chemical_abundances)
cleaned_df = cleaned_df.to_numpy()


# tsne_train_loss_history = [0.39010712508838663, 0.255778748545131, 0.241530631802349, 0.235419270714311, 0.23037671268240048, 0.22805633921830326, 0.22445993931541539, 0.22340891735229118, 0.21954546021408172, 0.21869208328985137, 0.2161466563272818, 0.2152717674450305, 0.21381177625054962, 0.21289310196941985, 0.21172704557493185, 0.21115846104908226, 0.21092191379717926, 0.20983450311828794, 0.20971348749058982, 0.2084066250947674, 0.2074414159952637, 0.20769130726762167, 0.2073925766431419, 0.20757838889240854, 0.20612618312338699, 0.20649489680044555, 0.20630386111934668, 0.20555091442676485, 0.20459925674085114, 0.2050193232127395, 0.20384250249830796, 0.20437411882249829, 0.20431422643361807, 0.20338509159854193, 0.20341252355340864, 0.20328567099763545, 0.20222856693230784, 0.20307274892190563, 0.2027386922473574, 0.2024504513625773, 0.2023831967795008, 0.20151110450097307, 0.20122340491264268, 0.20173779760240235, 0.20072352183377987, 0.20143774361034888, 0.20213130152855863, 0.20079106652595988, 0.2013478367804003, 0.20010310891798394, 0.2012434914041486, 0.2008692891939287, 0.2005227395534444, 0.20017181462419426, 0.19859371452898164, 0.20064645627008112, 0.19917845543824814, 0.19932250889552808, 0.19930559102816173, 0.19982219996543327, 0.20009060795111816, 0.19807911442271517, 0.19885195512484558, 0.1984717362299556, 0.19892581780141655, 0.19800303659710466, 0.19906954220223796, 0.19793323990308426, 0.1986390497131748, 0.19740188890281113, 0.19786752532257493, 0.19768936627029937, 0.19754862050242114, 0.19788594757841044, 0.1969637590839505, 0.19813791251946478, 0.1969569288586491, 0.19696266518134908, 0.19820633252047737, 0.19647981270405396, 0.19765833525262694, 0.19821634865054646, 0.1973941842801755, 0.19653038922284127, 0.19683356128704807, 0.19731363553526832, 0.19669178504193816, 0.1962225415116954, 0.19683613510010392, 0.19720642656183587, 0.19725983197297836, 0.19641590196536632, 0.19520706695138815, 0.1956107910897504, 0.19631486818938945, 0.1967266162363407, 0.19697521777752758, 0.1954843334175312, 0.19623953942285996, 0.1946552013814899, 0.19557076653962138, 0.19466507132570313, 0.19558512002610315, 0.19481516464797918, 0.19430648709832174, 0.1951553719785306, 0.1948662722108077, 0.19679694955357338, 0.19534573162391763, 0.19508058495362707, 0.19473735945514484, 0.1954530022976619, 0.19554490771288477, 0.19499926511452867, 0.1951101684218178, 0.1932423341816486, 0.1935805040096202, 0.19490493952992052, 0.19436037476553003, 0.1935354718746905, 0.19435888818077104, 0.19353742330244725, 0.194637754816161, 0.1945325695704431, 0.1936999950912697, 0.19268456953373542, 0.19314643949775523, 0.19302993941047975, 0.19374188088201694, 0.19304633391865944, 0.19338825184775926, 0.1938186638567515, 0.19384406171352356, 0.19415679692986101, 0.1932432338672183, 0.19218515570734088, 0.19287964749286382, 0.19300645698896665, 0.19132957780180435, 0.1928210183071034, 0.19329194536584124, 0.1918018747913231, 0.19149502410018976, 0.1927676488706517, 0.19240566650518906, 0.194018622309546, 0.19183174761070487, 0.1926391339923529, 0.19126313384345492, 0.1937468913081549, 0.19062399250632645, 0.1912668439810676, 0.19166794014846034, 0.1915116608866264, 0.1925462884094603, 0.19033253438861475, 0.19326480238153987, 0.1906243050267141, 0.1918108491923314, 0.19217780515338995, 0.19120452449919886, 0.19172319342935315, 0.1909115589090597, 0.19305481640216493, 0.1913540379616347, 0.19071263747758743, 0.19139806282191754, 0.1912051526773536, 0.1907712002308127, 0.19060846203400436, 0.1897650693029007, 0.1914862814223101, 0.19076962928182026, 0.19004178939313332, 0.19159767200836583, 0.19022408894266896, 0.19129025841081584, 0.18867936568674562, 0.1908433184620869, 0.19017484022429762, 0.19070686358423994, 0.1896173114285226, 0.19249728015302695, 0.18981798754545776, 0.18975006681069453, 0.19015772171155484, 0.18991813497668342, 0.18959918586483404, 0.19008280397066926, 0.18951682400842326, 0.18865324441860784, 0.18955442059079244, 0.1892464633484882, 0.19008763546267532, 0.18855285525112728, 0.18935241419826151, 0.18735680726535361, 0.18969690270176015, 0.1901015216688195, 0.1882701246730777, 0.18940762588522667, 0.18968490472949462, 0.18798959540019997, 0.18819974401469228, 0.18920958292890283, 0.18816153810070382, 0.1884139442414466, 0.18797698312035793, 0.1884104012396829, 0.1889152218960462, 0.1892066951953801, 0.18926877658810018, 0.18861890856400038, 0.18889715398935644, 0.1895092663273301, 0.18774560891412906, 0.18940783183599072, 0.18867250943199035, 0.18742092207282285, 0.18921283259069654, 0.18924755202583365, 0.1896415602643118, 0.18852340730125708, 0.18706073812359664, 0.18852574503736078, 0.1879016331523107, 0.1897716185975194, 0.18872230190641004, 0.18897548324253002, 0.18736515590662703, 0.18798680246584143, 0.18846847975803407, 0.18835189998421428, 0.18781206553885504, 0.18752506700180155, 0.18835195816206926, 0.18723438879610915, 0.18819500244271897, 0.18789687061365015, 0.18733206740909164, 0.18721024455113516, 0.18761753094513284, 0.18792759610576637, 0.18735346098139907, 0.1873259049492408, 0.18824962649150231, 0.18848294182411007, 0.1870717572290232, 0.18875347812053417, 0.18783694923266828, 0.18751679788792194, 0.18798060336464845, 0.18873183309822658, 0.18869338551030787, 0.1874864528333912, 0.1859133069329946, 0.1875829695709274, 0.1879931834204094, 0.18700426240437096, 0.18668242229919596, 0.1868292352681164, 0.18668334327643157, 0.1864615751484509, 0.18668606616898872, 0.1872289953748483, 0.18661657564269124, 0.1871048741332535, 0.18623656903787478, 0.18679804001380512, 0.18671149050595556, 0.18793310836737698, 0.18659480278803062, 0.18716654463944724, 0.18668284134135074, 0.18680514491617622, 0.18757802686388386, 0.18699090237204014, 0.1871083900760933, 0.18647572629454778, 0.1875156707362212, 0.18764888500604596, 0.18672438158297328, 0.18780640433407833, 0.1879062849600629, 0.1863894010353181, 0.186135743909317, 0.1876080887963519, 0.18709814839415095, 0.1873455528152898, 0.1869182380375259, 0.1873535846424509, 0.1865229317820342, 0.1867609734059413, 0.1875363293025481, 0.186427963943912, 0.18777250334318868, 0.18666840664916082, 0.18678485882990978, 0.1873812097637334, 0.18688397456412087, 0.18644173948815018, 0.1858056301394484, 0.18726782557726424, 0.18684508671027086, 0.18689412515855583, 0.18555342500912653, 0.18608645957017, 0.18698213681210252, 0.1878792333581982, 0.185490095442436, 0.1874918775594442, 0.18652289528871313, 0.18707635906351824, 0.18686834903665828, 0.1864071493867229, 0.18634574452942504, 0.1858334292255832, 0.187363698607786, 0.18618003114533752, 0.18556598941916908, 0.18594185918941286, 0.18601738550066638, 0.18635805740710984, 0.18681646585108336, 0.18704036780776254, 0.18645604220450934, 0.1864400265713466, 0.1869590570958897, 0.18583915822624725, 0.186841064455155, 0.18592687305520705, 0.18627300733625687, 0.18584040794052745, 0.18581792829070368, 0.18752676107986022, 0.1860970731067002, 0.18680056336613587, 0.18590068993984926, 0.18678445764266044, 0.18701276843435993, 0.18539514720876182, 0.1867804482208622, 0.1859839686177756, 0.18559444363108848, 0.18522369656153956, 0.18554533372979354, 0.186100353700451, 0.18671074451747757, 0.18580939048848752, 0.1854927035841435, 0.18477047117747936, 0.186463467137391, 0.1857491845976061, 0.18633038270988994, 0.1848722840062854, 0.18518763389061382, 0.18713932576818065, 0.1867592860355754, 0.18613028242951485, 0.184891799983313, 0.18570211913696244, 0.18548678737908625, 0.18596413842201304, 0.18599868713095488, 0.18501361338795233, 0.1866419178490963, 0.18611954375617365, 0.18549233529207837, 0.18565794624556828, 0.18501542045507574, 0.18656527826005914, 0.18516050021272143, 0.18617863080011685, 0.18635612910291918, 0.18609842064400411, 0.1859885172848741, 0.1868471809828359, 0.18636141502858988, 0.1855466183325345, 0.186854461090988, 0.18577481763318723, 0.18680853545843812, 0.18470808506274616, 0.18519042118347664, 0.1859901304254433, 0.18598157957399905, 0.1842146274850103, 0.1853310760574991, 0.18508895101682754, 0.18509262748464939, 0.18460118937206568, 0.18524011300132598, 0.18568896738144144, 0.1856268158144801, 0.18448519926197954, 0.18620509268705265, 0.18473015435469037, 0.18542609253668857, 0.1855750282739042, 0.1854289164341665, 0.18496210192675125, 0.18673236272125643, 0.1848497177774764, 0.18548240479833383, 0.18531494999837372, 0.18542239630971996, 0.18526707824345476, 0.1850171670127337, 0.185901344819674, 0.18570425393169335, 0.1834999124097792, 0.1855485672595138, 0.18512589190469952, 0.18448383993863507, 0.18554567944140757, 0.1851470931408448, 0.18543015878189312, 0.18470914121774254, 0.18559823798268768, 0.18550367413086036, 0.18507522882250818, 0.1842240462208606, 0.1848773548684347, 0.18546046656293147, 0.18460350829613503, 0.1851357076197709, 0.185638765189083, 0.18513821346777248, 0.18455008116707042, 0.18530034428728517, 0.18515628290586844, 0.18538887952260666, 0.18488475780404615, 0.1859204518422401, 0.1861580857170003, 0.18439677368580462, 0.18388680266772173, 0.1852858544388739, 0.18473364841155399, 0.18475028731702947, 0.18496337572395227, 0.18440134366905372, 0.18451515203055954, 0.1846228172361686, 0.18474131384087478, 0.18462134090493101, 0.1845520994936844, 0.18438954615296468, 0.18527601459413817, 0.185248984084723, 0.184653271499105, 0.1845846739662656, 0.18513568644830258, 0.18447883781614666, 0.18434435430216073, 0.18424800698200167, 0.18445511420038072, 0.1845797886591316, 0.18333508904648554, 0.18494341808425294, 0.18498474923995784, 0.18477884731283642, 0.1850493782337576, 0.183965835653246, 0.1840081440542355, 0.18401363500359078, 0.1849121717971651, 0.18472774622954785, 0.1858371363170776, 0.1842193931065162, 0.18542759757066327, 0.18383760263382234, 0.1840036602526518, 0.18414439454945164, 0.1836633057624215, 0.18328802197096514, 0.1847002195790204, 0.18468273054387965, 0.18485061745191672, 0.18529500425267018, 0.18418247251534126, 0.18288776746487295, 0.18383912511536624, 0.1850769017613738, 0.1841722802590893, 0.18400476783551864, 0.18373304282508657, 0.18433398442282084, 0.1832343108595348, 0.18348486578502793, 0.18530463860183452, 0.18365061689000994, 0.184002476067199, 0.1845265627875607, 0.18450818780276265, 0.18423595212623103, 0.18437483552719516, 0.18396988487045995, 0.1842600589619339, 0.18567257515478994, 0.1842230499632124, 0.18341397040498755, 0.18513664873900482, 0.18301642482070965, 0.18325011097843522, 0.1852552691772686, 0.18524657519832916, 0.18410799158025476, 0.1846381166431099, 0.18313345064441283, 0.18446230227836474, 0.1828662807416663, 0.18336206245537218, 0.18444028861007694, 0.1846232556334727, 0.18608825365484175, 0.18340468831152776, 0.18437801896679953, 0.18418629293979902, 0.18445339564875907, 0.1841699349282792, 0.18317809949708097, 0.18463667084317076, 0.18378429508688238, 0.18348631912847818, 0.18383404148222396, 0.18334371649717696, 0.18409214237622376, 0.18416137297747873, 0.1839798044084176, 0.18326248366554587, 0.182970403594356, 0.1827369494914154, 0.1838499372739469, 0.18400724948040179, 0.1835585996888111, 0.18385441719804568, 0.18497486554870274, 0.1838691984042798, 0.18453028288153966, 0.18348970441877357, 0.18355141829959984, 0.18383066908645793, 0.18424043753935265, 0.1842835980454769, 0.1831743062984882, 0.1836733725201568, 0.18432650818449217, 0.18282754018327388, 0.1832222957145964, 0.1832297635747085, 0.18367010482983892, 0.18392447152111224, 0.18400593472921392, 0.18359346322081463, 0.18370882004657474, 0.18294876006672758, 0.18494478937504727, 0.18342574859263783, 0.18393945511224885, 0.1835258116429359, 0.18345598766740348, 0.1831884144973217, 0.1830134083711591, 0.1840023339903197, 0.18351147630406295, 0.18451137340369755, 0.18340081242479, 0.18433279835093377, 0.1826433585099033, 0.18383345663084533, 0.18337578205765295, 0.18341450638158138, 0.1831039538765178, 0.18321006603144452, 0.18281603590587725, 0.18450588553496175, 0.18327933317053816, 0.18293352191269607, 0.1833839364718782, 0.18387768322718634, 0.18298975257799102, 0.18396972179239224, 0.18308170469108695, 0.18296558780037658, 0.18529899082023396, 0.1841326573514023, 0.18399417007603383, 0.18399300540599378, 0.1837449762501383, 0.1839337389482413, 0.18371468773187521, 0.18540047313017755, 0.18366251733974573, 0.18440752025545912, 0.18360113364946443, 0.18374707964992887, 0.1833329979647211, 0.1833387068256127, 0.1837406097491511, 0.1838969673853724, 0.18309261049582537, 0.18326946173498457, 0.1832071696303407, 0.1834574213340646, 0.18344474662604757, 0.18273280960404675, 0.18253595295777927, 0.18374313417546947, 0.18424916233227745, 0.18348196095117347, 0.18361748563663696, 0.18283077712193108, 0.18301598273400757, 0.1830195447703937, 0.1839524263298906, 0.18365184300438553, 0.18237781686591056, 0.18267513116890788, 0.18357154783964674, 0.18344206362350604, 0.1836047017702966, 0.18401278957498643, 0.18282873643745415, 0.18299745797078154, 0.18281100489145183, 0.18320227896105906, 0.1825505786895556, 0.18331240901727816, 0.18269134705235313, 0.18309631058692363, 0.18434575971682562, 0.18164129563238543, 0.18320293990863573, 0.18270494200417794, 0.18324237400595625, 0.18402481118944836, 0.183528328697136, 0.18293801257110656, 0.1824474204469363, 0.1827623366305698, 0.18311834927856704, 0.18317403770252574, 0.18252651700362552, 0.18250245673446874, 0.1828887350898993, 0.18320150557643616, 0.1830858813010424, 0.18400179701096644, 0.18333996918623652, 0.1831493768873025, 0.18215409223405124, 0.18368671047953747, 0.18393935807607414, 0.1836100806943937, 0.1830169574584818, 0.18389581740280897, 0.18252173537135669, 0.1835756326687328, 0.1829539598107329, 0.1820585151900721, 0.18348678918115072, 0.18374425230901284, 0.1836751809695524, 0.18289569793542404, 0.1823624852805188, 0.18256690375247006, 0.18247049819101843, 0.18374202169121243, 0.1838281814194534, 0.1834232166962624, 0.1829176380171948, 0.18278914818896216, 0.1825989222388991, 0.18278369030840982, 0.18280214385902102, 0.18208502857054185, 0.1844462371672034, 0.18286607544976305, 0.18370413108441477, 0.1833356889782088, 0.1816968442276048, 0.18202900526388077, 0.18354387432548266, 0.18280057148101286, 0.18140927437920756, 0.18298343280287868, 0.18251693867655025, 0.18172103018892988, 0.1829369595635061, 0.18214867007332622, 0.18298108204648336, 0.18289405562245684, 0.18340916848269934, 0.18221210264266582, 0.18357798519915539, 0.18253766929687507, 0.1836415876599848, 0.18272428941856675, 0.1823133073084402, 0.1829744196136659, 0.18239469577145367, 0.18255588432095193, 0.18316935822929703, 0.1831963726934481, 0.18227070619406627, 0.18302058490794948, 0.18380930152802322, 0.18242963765002104, 0.18176532490279804, 0.1826296969675058, 0.18351287524363968, 0.1820376999317304, 0.1820233603358598, 0.18283435208957363, 0.18328344405356278, 0.18207115564623036, 0.1830886152684711, 0.18239758047666513, 0.18274868878958356, 0.1825110940825406, 0.18207937937661972, 0.18317959771206882, 0.1831064350016577, 0.18242665001784047, 0.1824849697137504, 0.18274679864144716, 0.18311936057204226, 0.18188518846005622, 0.18224853367354607, 0.18265937796490392, 0.1836618816303222, 0.1814693376690147, 0.18187633498671768, 0.18205373134639036, 0.18087905013331537, 0.18297193081813962, 0.18220352912618704, 0.18259307137903405, 0.18227087331655997, 0.18247748222359264, 0.18154672802549665, 0.18223055046497194, 0.1822535561439268, 0.1822990499789101, 0.18176661909352193, 0.1827100097478678, 0.18349402374109736, 0.18210501863465156, 0.18089183381824642, 0.18207381659474167, 0.18240114175291286, 0.18223925120836412, 0.18284741400741944, 0.18185821394713253, 0.18203048355611964, 0.18214695541143186, 0.18174695422174114, 0.18143478633575902, 0.18229609991960294, 0.18157640349380608, 0.18464844125025356, 0.1820929427910478, 0.18205787312575794, 0.18155030164091643, 0.18257607402879153, 0.18252452390959997, 0.18250472212943586, 0.1822663348651429, 0.18156571550711692, 0.18146209495789137, 0.1820364324126271, 0.18203838142085105, 0.18204834628108724, 0.18164798030175536, 0.18221746068577208, 0.18206357632066913, 0.18197559092806795, 0.18204518807963604, 0.18255653041299796, 0.18171865925269626, 0.18165517952583912, 0.1817945462535179, 0.18118285362212455, 0.18216967984585475, 0.18133112978735802, 0.1811109394974719, 0.18129588362972787, 0.183180311622261, 0.1825116702440793, 0.18192387395126253, 0.18116886936369092, 0.1813685883116763, 0.18183686199991508, 0.18175033967452583, 0.18204785518827338, 0.1819125046857985, 0.18169532762238708, 0.18149879267158925, 0.18176747895140066, 0.1825227345048433, 0.18173732251469768, 0.18253876590392207, 0.18155586551570208, 0.1814105762403178, 0.181910264988629, 0.1813712348898991, 0.18150220492064387, 0.18099775860295178, 0.1822351392635942, 0.18094380200020505, 0.18201623622190874, 0.18160916279799125, 0.18116000452722925, 0.18171680457063674, 0.1824218266814629, 0.1821137689439646, 0.18165318466891575, 0.18280055676348686, 0.1827871920000457, 0.1820442570814836, 0.18189852779169258, 0.18225611466851813, 0.18201874812987165, 0.18228310979532691, 0.18202218894031996, 0.1813873459165363, 0.18193452606119973, 0.18129468764265333, 0.18203484717236487, 0.18293637734757073, 0.18175817943263048, 0.18184184627194983, 0.18153287444409213, 0.18291533160257734, 0.1823605387764111, 0.1817363468141746, 0.18272028549580785, 0.1825273302304076, 0.18194615779700135, 0.1825681004640689, 0.18125828849974612, 0.18109098513093075, 0.18196604329923224, 0.18130591722962497, 0.18258022038457072, 0.18136795149821575, 0.18259312037290348, 0.18073896131644426, 0.18225125080218404, 0.18135336707990604, 0.18207006627774877, 0.18117602857978735, 0.18197605462584987, 0.18069946774135417, 0.1810937614902655, 0.18198658898444964, 0.1813163586198478, 0.18125350989244973, 0.1809318401907172, 0.18146197368409708, 0.18224280498339246, 0.1816485248446527, 0.17994641101345185, 0.18271659959915354, 0.18245853740098417, 0.18238411794362142, 0.18124630681536572, 0.18191517455675432, 0.18148060765238996, 0.1815688860933707, 0.18273183014067162, 0.18052668801383429, 0.18104090171158915, 0.1830068584677619, 0.18141241844408773, 0.18085867437408898, 0.1826333326148937, 0.1815267020579244, 0.18165359299456585, 0.1829320204679547, 0.18197812303256325, 0.1809801323333361, 0.18267097786170194, 0.18303756549285538, 0.18192177482850255, 0.18093177499688493, 0.18218994612845682, 0.18094485802164853, 0.18154720325445575, 0.1809139268570034, 0.1813402950977387, 0.18179620888432801, 0.18091016326930723, 0.18213342246041286, 0.18174536631598626, 0.18145703323520995, 0.18108518266172136, 0.1818060726127682, 0.1807469945826375, 0.18060947649486392, 0.18136877583770936, 0.1823653999794784, 0.18215717442166202, 0.18197805256784447, 0.1823369088012382, 0.18068110346860905, 0.1825290161572896, 0.1812151573830433, 0.18146305098162532, 0.1813396194916219, 0.18238272419368654, 0.18183324850004437, 0.18212107410886055, 0.18124036911274857, 0.1819574977520627, 0.18082779687321188, 0.18127883285277366, 0.1818762001372744, 0.18086042077037057, 0.18047230243371237, 0.18137104577903868, 0.18210858990733142, 0.18246980037505975, 0.18120386140805414, 0.18177170453519265, 0.18122154107210625, 0.18138621169877592, 0.18196515199410496, 0.18139076452604624, 0.1817297122905676, 0.18151831706801222, 0.18186915885837646, 0.1811336646675485, 0.18126176394267884, 0.18088940665069086, 0.18285453579198593, 0.18260240760703575, 0.18160750862998115, 0.18213547006070244, 0.18157038147703777, 0.1820818126698001, 0.18107518392357444, 0.18043257947044292, 0.18187260187244708, 0.18102620349399395, 0.18088767460689079, 0.18267585008621964, 0.18099267235662506, 0.18107351868180577, 0.18119485087988224, 0.18054692445182224, 0.18242766845082942, 0.1814187589276851, 0.18119374838204083, 0.1822088927317702, 0.1815682415138109, 0.18209967496183385, 0.18080736137133607, 0.18103050783168603, 0.18103829659596704, 0.18110082829000346, 0.18143436835980128, 0.18171893030825736, 0.18160158749014546, 0.1813614510461066, 0.18227016829653703, 0.1813668729219188, 0.18025191604592497, 0.1817835004230496, 0.1818406252025338, 0.1814918430066196, 0.18065069122140479, 0.18049283783758485, 0.18108081124264983, 0.180564847055218, 0.1815486703905784, 0.18193116046550054, 0.1817708844727296, 0.18214028642895919, 0.18127197193034564, 0.18142246678488258, 0.18148259251955884, 0.18090352410251223, 0.18037646836390087, 0.18098782651881515, 0.18156274505428688, 0.18130814996312541, 0.18103219186990788, 0.18187926015956093, 0.17992043007598962, 0.1817013046897119, 0.1811928694717326, 0.18083913007940167, 0.18097912063363758, 0.1811398240345375, 0.1812134916304349, 0.18101459217842578, 0.1811493642934808, 0.18158193697084615]
# tsne_test_loss_history = [0.24782256328381622, 0.22471766797563816, 0.2139841369713362, 0.2066952604002653, 0.20172307247265997, 0.19808547692955233, 0.1947914848769146, 0.19290876738556542, 0.19084991019609648, 0.18976924734542686, 0.18772172152165842, 0.18581618085281554, 0.1850832479379323, 0.1833488593484027, 0.18117246341091447, 0.18302058440350477, 0.17929584732101606, 0.17809660282467188, 0.17964277557332858, 0.17778606564746932, 0.18170870691866162, 0.17548596313268244, 0.17642519822277897, 0.17556294571485748, 0.1747834151294599, 0.17523235796328474, 0.17530385104537238, 0.1734696915132194, 0.17367035543659526, 0.1720547189966577, 0.176171325006092, 0.17067780348766623, 0.1725589741106114, 0.1753667136001473, 0.17172196276249152, 0.17101399439747567, 0.17248855855347503, 0.17389732583622192, 0.1707159190404014, 0.16965029826174574, 0.17026243110479244, 0.17188926545547725, 0.16900811334563814, 0.17009837109734788, 0.17040081420517772, 0.17314793210063611, 0.16841087564634036, 0.168059458265499, 0.16789747109699474, 0.16748091072003246, 0.16956461464843683, 0.16893059785177578, 0.16679643221020615, 0.16674732739414164, 0.1691788085225966, 0.1717844430570477, 0.16673854473576108, 0.16686474375109314, 0.16565225715386403, 0.16586265185434507, 0.16574676493724275, 0.1664162155667432, 0.16594018594363685, 0.16518650465947501, 0.16631119257939744, 0.16932295470202297, 0.16603960963005385, 0.16868705371838313, 0.16766516405284582, 0.1660351673968632, 0.16483754099946724, 0.16430391187733107, 0.16538674041888698, 0.16354423650578703, 0.16505497001235875, 0.16374689201367765, 0.166088783550469, 0.16356471298827482, 0.16455420540763477, 0.16349611943154674, 0.17054720315598823, 0.1712452794336401, 0.16443938586194964, 0.16384066274185338, 0.16269050140233335, 0.16444210046355934, 0.16268094716662276, 0.16209703468284611, 0.16357331456351998, 0.1645849979013052, 0.16211513761941382, 0.16385414919919006, 0.16105768828165176, 0.16191808180474884, 0.16261640836058802, 0.1618183033784361, 0.16254595143143122, 0.1638431640613773, 0.169652948087069, 0.1615451048742314, 0.161886224167685, 0.16591232837274808, 0.16065085207284388, 0.1615811266805492, 0.1611065599976815, 0.16336884686542574, 0.16192125872853153, 0.16451536985264806, 0.16101372638944952, 0.16211227384760407, 0.16508518023949686, 0.1649520948143624, 0.1603379297878135, 0.16032616124366725, 0.16154321998223112, 0.16198837201328833, 0.1601148362130393, 0.16035585257886323, 0.15968048273893837, 0.16280903438482966, 0.16249665833177476, 0.16121772291170278, 0.16144561676209118, 0.16350495200789916, 0.1608323430523336, 0.15877079039254527, 0.1592785698345036, 0.1611928511770557, 0.15815809194250785, 0.15900092713061573, 0.16001994066559985, 0.1604358322075116, 0.1634031954113998, 0.16109356506276182, 0.1598463135723564, 0.15986589958206213, 0.16144453598914418, 0.16028031668081114, 0.16000581148961351, 0.160027250943576, 0.15928999490963877, 0.15844374757430219, 0.15940684844796807, 0.16153187101770228, 0.1593411408164173, 0.15875286559104348, 0.15897217358477223, 0.15941022278222738, 0.16060334926988543, 0.1612515036760815, 0.1579182478071145, 0.158616596111226, 0.16010235402574638, 0.16076451623572002, 0.15911689277085478, 0.15816134156085337, 0.15818100649958217, 0.16109450189613406, 0.15980691472632183, 0.16463204318035476, 0.1585752846603366, 0.15792189111960309, 0.15936195163324116, 0.16048807502260326, 0.15816032888619636, 0.15831263157920203, 0.1595108337482517, 0.15811047193570385, 0.15768441724318263, 0.16147051447235738, 0.15757294159563845, 0.16176768366254787, 0.15739733803104866, 0.1583599507922201, 0.15820910314120884, 0.1596647465813084, 0.15760514347517818, 0.15763973672037684, 0.15834311357071207, 0.1571454641635728, 0.16181408873976885, 0.15811647909686707, 0.15718245915054424, 0.15771765542478164, 0.1562136306102835, 0.1592517034253777, 0.15712880046527725, 0.15668858146143527, 0.15811104954697963, 0.15773844758830535, 0.15766145976493248, 0.15985357430295605, 0.1568382242390189, 0.1590979591965199, 0.15745758352424696, 0.15747588235997448, 0.15651692431850642, 0.15893481704251156, 0.15753977383439316, 0.15674335452975557, 0.15991694257239247, 0.16098049228829467, 0.16014310443086163, 0.1582884191275934, 0.15705290165920718, 0.15857896543690078, 0.15626888542698533, 0.15815177177126633, 0.15856916212326444, 0.15721058646811903, 0.15635224026351874, 0.15708219797924897, 0.1576700767771997, 0.15696206879019714, 0.15846056789310017, 0.15788711381649, 0.156765337770098, 0.15694603739326016, 0.15812971292668662, 0.1564363332024931, 0.156912865344015, 0.15565927357896048, 0.1572846160690567, 0.1573608176988405, 0.15711146686799968, 0.1560974136462885, 0.15816279259585495, 0.1596540449161215, 0.15592974663802403, 0.15789372943960225, 0.1588909312748269, 0.16067328060355293, 0.1589648920602112, 0.15530540053972836, 0.15586141494865702, 0.15620511976579887, 0.15738521599456645, 0.1558993416079316, 0.15863654557816537, 0.15504955637779508, 0.15632489866710741, 0.15546482367295478, 0.15985356869950956, 0.1578876391432142, 0.15821248568754992, 0.15750559646285825, 0.15985827456678847, 0.15679256414918852, 0.15722059582332024, 0.15891361431607814, 0.15693604456460913, 0.15670641580817546, 0.15572519398567153, 0.15639675335734698, 0.15707829834441855, 0.15680733047098278, 0.1564562994091028, 0.15541754584141676, 0.15646148915763414, 0.1549901737385643, 0.15778814785096504, 0.15434790312756416, 0.15546369446163516, 0.15806039449710452, 0.1603324929745907, 0.15499058605595928, 0.1562311041223366, 0.15654406208523963, 0.15592567831775314, 0.15556574202669163, 0.15570874656872458, 0.15516719696330697, 0.15608554900720853, 0.16074467529479622, 0.15555042883578718, 0.15734062189170692, 0.15735115383033627, 0.15894337313746965, 0.15663367315974913, 0.1544712348776965, 0.15792659167501505, 0.155244940715537, 0.1562686278687692, 0.15699260070190485, 0.15502400539859665, 0.15645723217315985, 0.15635317621046693, 0.15716399454405872, 0.1570815093373784, 0.1573184188849727, 0.15655490655707005, 0.15730356703744652, 0.16121104715364937, 0.15715099530722795, 0.1554179681977172, 0.15576874176871142, 0.15562356193815113, 0.15827183663531225, 0.1571873102817477, 0.157851833116884, 0.15604306993941142, 0.15711070662053794, 0.15592472798157728, 0.15940826395088672, 0.15445659795044347, 0.15565231485965828, 0.15520969841818041, 0.15484173749485367, 0.15567011248351365, 0.15809662571039373, 0.1546212409600466, 0.1571495913222575, 0.15458906939031117, 0.1582086660083919, 0.1561255083319952, 0.1559926950651989, 0.15454013309553458, 0.15738773151913324, 0.15571386052994673, 0.15872566409470534, 0.1587012387193644, 0.15504313819965934, 0.15470750178565695, 0.1554485733059052, 0.15578447488757066, 0.1559350439577036, 0.1553541917536523, 0.1556902049529668, 0.15494938370200267, 0.15581469169583703, 0.15601754829233552, 0.15594302187158163, 0.15696237216312653, 0.1543384053180588, 0.15437616195363182, 0.15375705188878055, 0.158399817636769, 0.1540400066031713, 0.15656170630876584, 0.15701991452926028, 0.15516041161308072, 0.15751709421530632, 0.15472458868605618, 0.15566017044979888, 0.15439847500103718, 0.15546410344367181, 0.16152017817628486, 0.15517887765298016, 0.15535545848423232, 0.15478928767164435, 0.15595762222730408, 0.1559421306626169, 0.15567530518011444, 0.15672568021344035, 0.15508045564410872, 0.15508085886132855, 0.15657803555976607, 0.15689799622596567, 0.15552516365127836, 0.1548577846871662, 0.15667687153590526, 0.15653156798603224, 0.15528173699773024, 0.15563968123018201, 0.15554016909778615, 0.15380979587289778, 0.15516751297042228, 0.15441185740064775, 0.1559477244012764, 0.15913611730484356, 0.1569623333607899, 0.15798626880012023, 0.1605280060363522, 0.15397580437340772, 0.1564001682968393, 0.15524087410913054, 0.15521118713761156, 0.1549147389229028, 0.15537769415900388, 0.1547484591476965, 0.1537552028193298, 0.15471136284295633, 0.15672545968081758, 0.1536260073985542, 0.15543506406530014, 0.15719188078489513, 0.1615198342342917, 0.1547622026641141, 0.15657058777532787, 0.15285723136831217, 0.15630877857156347, 0.15548494625300333, 0.15470181275780256, 0.15477299796361502, 0.1548808469760186, 0.1562896036350316, 0.1550872711783817, 0.15541993429628834, 0.15394535075247548, 0.1549352134845269, 0.15403689745215565, 0.1537728228846009, 0.1553093209317945, 0.15563108116625368, 0.15641963559861652, 0.1570118923303487, 0.15508388750689972, 0.1556244527742947, 0.15581333827710214, 0.15675888667908716, 0.15503927769880949, 0.1559377079257474, 0.1547170634277104, 0.15494793232923626, 0.15694840287678344, 0.15495415954224992, 0.15481718533972771, 0.15325344505073768, 0.15647594867821363, 0.15416258086137985, 0.15527136285148593, 0.15395404999796292, 0.15614887489967677, 0.15441581543874847, 0.15518914948151596, 0.15737754282359648, 0.15403630343174052, 0.15311458056978403, 0.15615428883169608, 0.15423608643434647, 0.15881193166003207, 0.15594586055308338, 0.1574813436881365, 0.15539348753299737, 0.15467069416135354, 0.15692136110092786, 0.15283771702930218, 0.15884005356168385, 0.1560796683086541, 0.15452391030723517, 0.15647467843198568, 0.1566494159586039, 0.1564110161618988, 0.15869582445403185, 0.1558815492747981, 0.1569260836132807, 0.15340928953647204, 0.15328201116324405, 0.15551532656727826, 0.1560942942076345, 0.15480191555967465, 0.1534360609151521, 0.15838371893448258, 0.1539370630347812, 0.1555828849109187, 0.1548476373653192, 0.15621173801924793, 0.15461837679037543, 0.15657008841698902, 0.15364067803329223, 0.15385902775698812, 0.15362263475367557, 0.15741791272353475, 0.15576069328368183, 0.15310589433686816, 0.15383603519237113, 0.15536515085018485, 0.15199111246674057, 0.1603525552811422, 0.15459379211411484, 0.15368071892467258, 0.15358012346578298, 0.15421796274276883, 0.15367218746206457, 0.15241878548245918, 0.15293626542566177, 0.1546014322069442, 0.15616016808626404, 0.15243121122518405, 0.1565439059388322, 0.1531293056369687, 0.15306287137418345, 0.15403646245332253, 0.15542093263624976, 0.15572475600148686, 0.1523281754625712, 0.15336999959873385, 0.15463347575990732, 0.1543534265911033, 0.15518606439638477, 0.15526673431622, 0.15469094576200923, 0.15627073187444604, 0.15703876895032295, 0.15434939115421567, 0.15756365811990844, 0.1573945459087896, 0.15528209220615644, 0.1527813685022025, 0.15710500122416504, 0.1542050828916221, 0.15363976793954431, 0.1554876703665608, 0.15670144058094293, 0.1534867120259212, 0.1571930683583078, 0.1555728267050158, 0.15581475343780435, 0.15569070975226887, 0.15431976800522867, 0.15286057632315073, 0.15715765827695893, 0.1541069160972015, 0.15427603894707834, 0.15462880164975792, 0.15431953416845476, 0.1528468558743472, 0.15391239546479485, 0.1525373093124741, 0.151480715176386, 0.15524247209075995, 0.15265864440772384, 0.1574917760601437, 0.15251454159129418, 0.15252022064033965, 0.1538015634067438, 0.15221823533575637, 0.15465162476604213, 0.15449213692608546, 0.15652918994177437, 0.1547233919879846, 0.15357560156571723, 0.15359099766759735, 0.15291879177338344, 0.15246548526757792, 0.153896959156656, 0.15210585096054782, 0.15590450476262838, 0.1571389818045516, 0.15415986364779619, 0.1526011225745767, 0.1559118883133184, 0.1549076408068796, 0.15631644070090597, 0.15528079675944348, 0.1536010487359225, 0.15518895796884757, 0.15235913835276438, 0.15561415213391666, 0.1536133310816109, 0.1529438311211928, 0.1564434345236654, 0.1539422772693164, 0.15288613015582223, 0.15295610098071083, 0.1567593952939635, 0.15453931265526094, 0.15721714203363663, 0.15438278811311537, 0.1559770437533195, 0.15632922895712612, 0.15423375109870072, 0.1566665026753748, 0.15306814974286237, 0.15632860469089835, 0.1540162760880241, 0.1531598212491576, 0.1522145581571947, 0.15186567813154697, 0.1551238997405743, 0.1533076585551089, 0.15183172531687764, 0.15672806319284885, 0.15221072728449853, 0.1530378478451205, 0.1532848121925903, 0.15335202887234184, 0.15453053297555458, 0.15487783491486837, 0.15210097516583312, 0.151630897817937, 0.15635235821745821, 0.15260224296450237, 0.15439977600167262, 0.1544670806794612, 0.15518079048375347, 0.15539553543966128, 0.15491868158741667, 0.15269187494203737, 0.15794534863227824, 0.15513813234828105, 0.15409603659464916, 0.15299270887247385, 0.15376002250891063, 0.15209767668510046, 0.1542131184631281, 0.15333405332542782, 0.15481745762159765, 0.15219024542170048, 0.15238121089212275, 0.1519366265341532, 0.15377692202494034, 0.15640335135992933, 0.15312770381861998, 0.15342359841114742, 0.15332281235940043, 0.1547448604858288, 0.15064246983694893, 0.1516949356608325, 0.15435593817990276, 0.15499579190758275, 0.15352653872709018, 0.15297601357396756, 0.15214309103180693, 0.15255648000886074, 0.15526654069683382, 0.15327685570146163, 0.1532880844100194, 0.15597661839608692, 0.1527557691742198, 0.15394480003384764, 0.15254513946341286, 0.15387632247513905, 0.15366810969272468, 0.15153770417129714, 0.15401108168312333, 0.15961916813820043, 0.15183875530511903, 0.15252354392035725, 0.15546415122877275, 0.15353124506846408, 0.15292230627282052, 0.15259668220771766, 0.15187024222383969, 0.15392942805794854, 0.15402979377108098, 0.1529596249041767, 0.15335631143179168, 0.15239381209673014, 0.15482806225812856, 0.15318633801824744, 0.15176571902107314, 0.1610215939961171, 0.15143307115544732, 0.1522357966733471, 0.1521343842692432, 0.15286956144902103, 0.15482858257680723, 0.15346559571943405, 0.1548160632070022, 0.15211561172249077, 0.15478265693703297, 0.15298424787696133, 0.15563371178460952, 0.15370942895393927, 0.15320628619311108, 0.15445323756526025, 0.1532183466373109, 0.15464287700539203, 0.15311054302117053, 0.15309606263596054, 0.15351361623577464, 0.15342097682007183, 0.1562931478355173, 0.15220893058139742, 0.1525139896278888, 0.1521473344500424, 0.1532135341793478, 0.15295547135754373, 0.15502691532956187, 0.1524942775751372, 0.15396627915375638, 0.152005322053575, 0.153469712390715, 0.1545124625734763, 0.15300044842508706, 0.1519373214622338, 0.15501805949473318, 0.15425895584222116, 0.15514008917918576, 0.15159409491900275, 0.15319894111144444, 0.15265181123956617, 0.15637567129420568, 0.15268904518709853, 0.15513822403446537, 0.15164520501157844, 0.1542864621449026, 0.1504746696107787, 0.15545596693612146, 0.1517111855242953, 0.15359839213360077, 0.1524127732937747, 0.15198662057822224, 0.1547439135606884, 0.15353208845615868, 0.15144282416048424, 0.1536375462948784, 0.15340442642491084, 0.1535079461060582, 0.1536562780755839, 0.15222316285467802, 0.15338648836433036, 0.15245195076472196, 0.15484928080330837, 0.15650426159506797, 0.15561549935825572, 0.15545670913180493, 0.15512621275591768, 0.1528630273006883, 0.15518942836788505, 0.15118753237372895, 0.15286241616666876, 0.1525050584308784, 0.1531906560775061, 0.15428989516677794, 0.15312217063112582, 0.1542587543535261, 0.15219434339238305, 0.15510883418527852, 0.15074628474015342, 0.1528927638168015, 0.15501253756421243, 0.1583518007579388, 0.15385275835786844, 0.15204602013463075, 0.15425475443425368, 0.15540361468967087, 0.15447098030705775, 0.1510575627875767, 0.1532733900510569, 0.15321060592394403, 0.15540898975536185, 0.15328362435653348, 0.15117267647302463, 0.1533784483440106, 0.15027907363804155, 0.15230659159827772, 0.15136918970490995, 0.1568449577047807, 0.15104314706958905, 0.15202684122504947, 0.15441891752285547, 0.15235554927017483, 0.1551014606773891, 0.15052357932563198, 0.15298199054106795, 0.15299083061390806, 0.15210094801888774, 0.15355564825983276, 0.15258440371377271, 0.1561445853612373, 0.15242957506944949, 0.15428196189183535, 0.15414634917155778, 0.15228015326018865, 0.15372210710271433, 0.1514859860786255, 0.15260977018099395, 0.15261596672084174, 0.15422433367333388, 0.15237521109668156, 0.16141509431280723, 0.15840883030410735, 0.15185594893976645, 0.15494850753887598, 0.1557163935698745, 0.15314873488038225, 0.15334319484755138, 0.15288659126159657, 0.15486996771440892, 0.15323457537516838, 0.15109659312103393, 0.15265390274015336, 0.15525149094359095, 0.15443944422546718, 0.15326436658915468, 0.15109595850373256, 0.1552071521636899, 0.15321906786041267, 0.1546750956524246, 0.1530378409061952, 0.15304824017279578, 0.15392426361173248, 0.15478102780257824, 0.15148386299563396, 0.1536486025185585, 0.15220167179837105, 0.15252628316043798, 0.15291248302382437, 0.15294809941939838, 0.15238595129989155, 0.15117599140574325, 0.15606631242497515, 0.15321193771682554, 0.15458554771267552, 0.15172214107346227, 0.15168481525889949, 0.15568488083078408, 0.15068749073991464, 0.1518920996871191, 0.15179404162905197, 0.1580900857861152, 0.15315226976979843, 0.15360258100865612, 0.15195180005289413, 0.15372666871491164, 0.15573383520404852, 0.15372573327043734, 0.1514748380335439, 0.15122639890236425, 0.1533652106029075, 0.15245181665482765, 0.15180697586646005, 0.15176704853084233, 0.1547360949744396, 0.15248151284226327, 0.1516806884635763, 0.15276464579243731, 0.15278101203119235, 0.1504996428757582, 0.1520912223082553, 0.1518996784163668, 0.15276412543202494, 0.15429255288478094, 0.15146451053501775, 0.15366672624185373, 0.15364559155695245, 0.1534141575631517, 0.15286354082845727, 0.15351758132798565, 0.15124975948320563, 0.1520236946355549, 0.15123594908823537, 0.15197318574882673, 0.1524469790119601, 0.15318655503800452, 0.15307948614387437, 0.15529570918317523, 0.15106751504382523, 0.15134219311108452, 0.1531452915163365, 0.15350716624597735, 0.1534826582234178, 0.15549576326683312, 0.15373109178954597, 0.1521922668474891, 0.15074357438147115, 0.15018714516058437, 0.15282884417991713, 0.15059572776111166, 0.1503504554363499, 0.15193792761936897, 0.15282792420362606, 0.15131072508104218, 0.1523525847593038, 0.1529442560343787, 0.15236752879048013, 0.15155533190221657, 0.15384408950843503, 0.15228250229895982, 0.15102117577176583, 0.1517457906079571, 0.15086473812366147, 0.15038522831123785, 0.158994637517355, 0.15117447057528074, 0.15197110794246177, 0.1514828445244425, 0.15210654296059112, 0.15362831661501683, 0.152812776812415, 0.15477396113318573, 0.1517818321226033, 0.15604336658430987, 0.15263785241725594, 0.15877436631788636, 0.15226895616964797, 0.1600639953552161, 0.15405990513272333, 0.15153708536606478, 0.15520820745124975, 0.15171936551781773, 0.15502354876611982, 0.15187949194868167, 0.1518044189164537, 0.15811631532431922, 0.15101125086779252, 0.1540458293870181, 0.15189157028829745, 0.15191049320495503, 0.15256155450501493, 0.15192138080774276, 0.1552397927430084, 0.15209433415582527, 0.15134376562068155, 0.15108605014411583, 0.15138326711718142, 0.1515399506191431, 0.1502888757030052, 0.15270820973026658, 0.15132754366093545, 0.15199469226886536, 0.15106363525198405, 0.15305666652710107, 0.15204465961949537, 0.15496676540879123, 0.1504017395384749, 0.15388607152326356, 0.15164969613553517, 0.14987708409381698, 0.15336888324863154, 0.15017715176268553, 0.15269144763389284, 0.1510380615151139, 0.15546357180402803, 0.15194362447646784, 0.15234900898976858, 0.15118184897603062, 0.1502427305383382, 0.1537770840663738, 0.15144615604098532, 0.15149183944994493, 0.15289614332771057, 0.15315226916438138, 0.15020800626319322, 0.1528859590175523, 0.1584359636926959, 0.15119633527296011, 0.15085265731507924, 0.1524533883664761, 0.15157739003008933, 0.15005064649535435, 0.1597512081154716, 0.15184292133124497, 0.15116869981111558, 0.15116881160293327, 0.15294178019467744, 0.15228340493795375, 0.15039690329841657, 0.15120928140503273, 0.15140689832612483, 0.15018897292859176, 0.15125741397750453, 0.15066232180447606, 0.14980031583873993, 0.15080548309666417, 0.14974995585622894, 0.15326921237955582, 0.1530222424258573, 0.1543145234492037, 0.15212569171728682, 0.15139111480685202, 0.15102370793806785, 0.15048698147611314, 0.15165077875533806, 0.1511647717812236, 0.151796451896744, 0.1522727793789216, 0.1508678172097106, 0.15282178926385095, 0.15187380077126286, 0.1521911015142501, 0.1529042509015562, 0.15254354433581294, 0.15453340075880878, 0.15281457895091483, 0.15162543912400694, 0.15179201703650924, 0.1510203600323776, 0.15049127426199188, 0.1513933545672879, 0.15006628848837392, 0.15001079492534425, 0.15123874510341515, 0.1555636728948179, 0.15441566735418139, 0.15125043131473676, 0.15120982516359022, 0.15142509688909578, 0.15267089351557062, 0.1507811596879121, 0.15224826736661914, 0.1527594691388321, 0.15164497974023172, 0.15379764658819636, 0.15485107809847173, 0.15148042417778063, 0.15135591040537585, 0.15387084093561823, 0.15143045303884242, 0.15278706822668564, 0.15208617966549637, 0.1523932928230636, 0.15062861950114637, 0.15142630472005253, 0.15005895494468768, 0.15230655126626144, 0.1503441586415519, 0.15212109100505242]
tsne_train_loss_history = []
tsne_test_loss_history = []


def objective(trial, X, y):
    print("Executing nn_objective...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    X_train = torch.tensor(X_train, dtype=torch.float32)
    X_test = torch.tensor(X_test, dtype=torch.float32)
    y_train = torch.tensor(y_train, dtype=torch.float32)
    y_test = torch.tensor(y_test, dtype=torch.float32)

    train_dataset = TensorDataset(X_train, y_train)
    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_dataset = TensorDataset(X_test, y_test)
    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)

    torch.manual_seed(42)
    model = NNModel(2, 64, 32, 19)
    MSE = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)

    best_mse = float('inf')
    best_weights = None

    train_loss_ma = None
    test_loss_ma = None
    convergence_threshold = 0.0001
    consecutive_epochs_no_improvement = 0

    # Training
    num_epoch = 3000
    for epoch in range(num_epoch):
        model.train()
        train_mse = 0.0
        for X_train_batch, y_train_batch in train_dataloader:
            optimizer.zero_grad()
            predictions = model.forward(X_train_batch)
            loss_value = MSE(predictions, y_train_batch)
            loss_value.backward()
            optimizer.step()
            train_mse += loss_value.item() * len(X_train_batch)

        train_mse /= len(X_train)
        tsne_train_loss_history.append(train_mse)

        # Evaluating on the validation set
        model.eval()
        test_mse = 0.0
        with torch.no_grad():
            for X_test_batch, y_test_batch in test_dataloader:
                y_pred = model.forward(X_test_batch)
                batch_mse = MSE(y_pred, y_test_batch).item()
                test_mse += batch_mse * len(X_test_batch)

        test_mse /= len(X_test)
        tsne_test_loss_history.append(test_mse)

        if train_loss_ma is None:
            train_loss_ma = train_mse
        else:
            train_loss_ma = (train_loss_ma * epoch + train_mse) / (epoch + 1)

        if test_loss_ma is None:
            test_loss_ma = test_mse
        else:
            test_loss_ma = (test_loss_ma * epoch + test_mse) / (epoch + 1)

        if epoch > 0:
            if len(tsne_test_loss_history) >= 2 and \
                    abs(test_loss_ma - tsne_test_loss_history[-2]) < convergence_threshold:
                consecutive_epochs_no_improvement += 1
                if consecutive_epochs_no_improvement >= 5:
                    print(f"Model converges at {epoch}th epoch")
                    break
            else:
                consecutive_epochs_no_improvement = 0

        if test_mse < best_mse:
            best_mse = test_mse
            best_weights = copy.deepcopy(model.state_dict())
            torch.save(model.state_dict(), "/home/fanqiany/data/fanqiany/tSNE.pth")
            print(f"Epoch {epoch + 1}/{num_epoch}, Test MSE: {test_mse:.6f}")

    return best_mse


def tsne_model(trial):
    torch.manual_seed(42)
    # perplexity = trial.suggest_int("perplexity", 60, 100, step=5)
    # learning_rate = trial.suggest_float("learning_rate", 250, 600, step=50)
    # perplexity = trial.suggest_int("perplexity", 70, 70)
    # learning_rate = trial.suggest_float("learning_rate", 400, 400)

    tsne = TSNE(n_components=2, perplexity=70, learning_rate=400)
    tsne_results = tsne.fit_transform(cleaned_df)
    np.save("/home/fanqiany/data/fanqiany/tsne_results.npy", tsne_results)

    return tsne_results


# Create study objects and optimize for t-SNE
tsne_study = optuna.create_study(direction='minimize')
with tqdm(total=1, desc="Optimizing t-SNE") as pbar:
    def callback(study, trial):
        pbar.update(1)
    tsne_study.optimize(lambda trial: objective(trial, tsne_model(trial), cleaned_df), n_trials=1, callbacks=[callback])
pbar.close()

# Print best parameters and results for t-SNE
print("Best t-SNE Parameters:", tsne_study.best_params)
print("Best t-SNE MSE:", tsne_study.best_value)

# Explained variance
cov_matrix = np.cov(cleaned_df.T)
explained_var = 1 - 19 * tsne_study.best_value / np.trace(cov_matrix)
print("Explained Variance of t-SNE:", explained_var)

print("Train History:", tsne_train_loss_history)
print("Test History:", tsne_test_loss_history)


# Plot t-SNE
def plot_tsne(data):
    tsne = TSNE(n_components=2, perplexity=70, learning_rate=400, n_iter=1000)
    tsne_results = tsne.fit_transform(data)
    kl_divergence = tsne.kl_divergence_

    plt.figure(figsize=(10, 8))
    hist = plt.hist2d(tsne_results[:, 0], tsne_results[:, 1], bins=(50, 50), cmap='viridis')
    plt.colorbar(hist[3], label='Frequency')
    plt.title(f't-SNE of Chemical Abundances (perplexity: {70}, KL Div: {kl_divergence:.2f})')
    plt.xlabel('t-SNE Component 1')
    plt.ylabel('t-SNE Component 2')
    plt.grid(True)
    plt.savefig("/home/fanqiany/data/fanqiany/tSNE.png", dpi=300, bbox_inches='tight')
    plt.close()


plot_tsne(cleaned_df)

