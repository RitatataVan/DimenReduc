import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics.pairwise import euclidean_distances
import os
import copy
import umap
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.distributions import Normal
from sklearn.metrics import mean_squared_error
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split, GridSearchCV
from tqdm import tqdm


class AutoEncoder(nn.Module):
    def __init__(self, input_size=19, latent_size=2):
        super(AutoEncoder, self).__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(input_size, 32),
            nn.BatchNorm1d(32),
            nn.LeakyReLU(),
            nn.Linear(32, 64),
            nn.BatchNorm1d(64),
            nn.LeakyReLU(),
            nn.Linear(64, latent_size)
        )

        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_size, 64),
            nn.BatchNorm1d(64),
            nn.LeakyReLU(),
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.LeakyReLU(),
            nn.Linear(32, input_size)
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)

        return x

df = pd.read_csv("/home/fanqiany/data/fanqiany/APOGEEDR17_GAIAEDR3_noflagfilter.csv")
chemical_abundances = ['FE_H', 'C_FE', 'CI_FE', 'N_FE', 'O_FE', 'MG_FE', 'AL_FE',
                       'SI_FE', 'P_FE', 'S_FE', 'K_FE', 'CA_FE', 'TI_FE', 'TIII_FE',
                       'V_FE', 'CR_FE', 'MN_FE', 'CO_FE', 'NI_FE']

# remove 'ASPCAPFLAG' and 'STARFLAG'
selected_df = df[(df['ASPCAPFLAG'] == 0) & (df['STARFLAG'] == 0)][chemical_abundances]

# remove outliers if exist
z_scores = abs((selected_df - selected_df.mean()) / selected_df.std())
data_no_outliers = selected_df[(z_scores < 3).all(axis=1)]

# standard scale
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data_no_outliers)

# save cleaned dataset
cleaned_df = pd.DataFrame(scaled_data, columns=chemical_abundances)
cleaned_df = cleaned_df.to_numpy()


# ae_train_loss_history = [0.3735684817281953, 0.2288576057902087, 0.22088993660088962, 0.2159310705963692, 0.21375106676964473, 0.21064950933653367, 0.20781193325148997, 0.2056034183605033, 0.2031961101597619, 0.20119858027924628, 0.20002427034203007, 0.19855815568513568, 0.19696713147303888, 0.19597842317333017, 0.19499596614946804, 0.19410472866560935, 0.19344376964902618, 0.1927942885631977, 0.1919333494237543, 0.1916161677026973, 0.1907863419930621, 0.19087385371370805, 0.18953281952518533, 0.18994363289905436, 0.18923248454012448, 0.18903912710029663, 0.18801787272913692, 0.18753381859656099, 0.18755326901137298, 0.1874925742045894, 0.1864293046978432, 0.18660229383848523, 0.18608084136051312, 0.18529112198433123, 0.18532494166823513, 0.18508774744283718, 0.1850130988477067, 0.18445987822592985, 0.18421113685711654, 0.1837214813225121, 0.1830460351641891, 0.1830757640747914, 0.18301855347757334, 0.1823418643093241, 0.18236892539566826, 0.18235947949739056, 0.18155837449440546, 0.18171180508025278, 0.18125853623141183, 0.18140002801225277, 0.18117547508662202, 0.18100628603478774, 0.18080975109845815, 0.18001827924154865, 0.18044706177979483, 0.18010693679460268, 0.17966874893923052, 0.17952700765047075, 0.17950678439748965, 0.1788334616707744, 0.1792361683199213, 0.1789484116143683, 0.17886069796401255, 0.17780658578452435, 0.17796722251249397, 0.17819740968080336, 0.17840568007120444, 0.1778602781729556, 0.17780496701247592, 0.17769044410195003, 0.17801869714983068, 0.17732828754236934, 0.1774030686764785, 0.17728155658714123, 0.17688011714436136, 0.17711966135488685, 0.1764856585878727, 0.17701647683907965, 0.17649000364249526, 0.17644947211566467, 0.1760514044787923, 0.1756780577715147, 0.1759337814322632, 0.17590107069123948, 0.17554358330573555, 0.17570488361783804, 0.17497554144302666, 0.17545231473402265, 0.17493263224444616, 0.17494073110179145, 0.17478263456160445, 0.17452872288161195, 0.17472958392363808, 0.1746069510297001, 0.17510091004391942, 0.17409855918635334, 0.17423283545745125, 0.17407186992120882, 0.17419354926325384, 0.1742106686518808, 0.17415078119221433, 0.17368463769669726, 0.17400197917480734, 0.17399167853817749, 0.17308437985180472, 0.17292671846136126, 0.17281926650295462, 0.17350010843863364, 0.1726468491533337, 0.1730118835334755, 0.17322459415606312, 0.1721047658657723, 0.17277087576493128, 0.1724670906563355, 0.17243173316235735, 0.1723058115145884, 0.17210221852066893, 0.1722726638753915, 0.171832446260167, 0.1720308621717769, 0.17161371663576708, 0.171913891617815, 0.17191104706193433, 0.17119992959266978, 0.17149301427635266, 0.17151649980630873, 0.17177067056550893, 0.17140615946998677, 0.17094064561280242, 0.1709969976153293, 0.17089171925210037, 0.17108500635631055, 0.1708869070395637, 0.17061166198399294, 0.17033839591091782, 0.17109472270137085, 0.1711602545014257, 0.17034479813433645, 0.17036267640263197, 0.17042744119632627, 0.16999822994892355, 0.1699888854940652, 0.16986506826999215, 0.16969390686489272, 0.1697319351658097, 0.17012995289397548, 0.169809906447216, 0.16953765038940385, 0.1694486702115748, 0.16954354208194522, 0.1696842604848409, 0.169260505349528, 0.16926181882083421, 0.16941963266966653, 0.16883875171539364, 0.1691350354265264, 0.16888733803268793, 0.16830276803325186, 0.16879497281497513, 0.16893324739849855, 0.16870971528866247, 0.1693864314301392, 0.1683628763392789, 0.1687311112693733, 0.16822184548277203, 0.1684870033837458, 0.16897030436607122, 0.16844208602748928, 0.16807349036330915, 0.16797562147310455, 0.1679790087355306, 0.16800054976578493, 0.1679881777865045, 0.1675395579775326, 0.16804341508445786, 0.1677264411494039, 0.1676802570464248, 0.1675642752266329, 0.16761373104766178, 0.16760754399850217, 0.16698202172282992, 0.16705403796756976, 0.16733547166936988, 0.1671532327339161, 0.16775209578159667, 0.1674589479096004, 0.16681045865970726, 0.16672700641424842, 0.16681752132709696, 0.1668803602895545, 0.16666428369398087, 0.16684876924241682, 0.16683287244348263, 0.16678630265317743, 0.16628818523893613, 0.1670711796695421, 0.16649217538569538, 0.16667412986467076, 0.16626348978677674, 0.1653529760633041, 0.16603352701288243, 0.1666870618277859, 0.16605409817887398, 0.16602989194533654, 0.16627360375878952, 0.16591805170013119, 0.16627101826764834, 0.1660287977344506, 0.1658202085934206, 0.16574071105537605, 0.16587827902403268, 0.16565610486528534, 0.1658966345078862, 0.16591002631689597, 0.16531068969742482, 0.16583308793448007, 0.16570325740907624, 0.16532515008518645, 0.1659109306645737, 0.16526264582068315, 0.1654297970204742, 0.16517999860074736, 0.16470738606475557, 0.16515022089326611, 0.16477585060453653, 0.1652885933543473, 0.16500355196779093, 0.16512765560044015, 0.16491631656135025, 0.1647364075536092, 0.1645545039760834, 0.16464367639213584, 0.1645352769139741, 0.16491788803231183, 0.1646779380881748, 0.1645251412218133, 0.16466132406137265, 0.16450010433061865, 0.16439500481359934, 0.1640242502751063, 0.1645218250907574, 0.16395282971956027, 0.16437443369323834, 0.16412818630402845, 0.16385542855598242, 0.1644103510119007, 0.16420512899352435, 0.164240996910981, 0.16391067321381173, 0.16386397534630653, 0.16450157960011094, 0.16374854862676616, 0.16367969530457138, 0.16360233457456722, 0.16336117673823045, 0.16362593868166259, 0.16383286728977542, 0.1635794411245387, 0.1633438465530962, 0.1634728693095784, 0.16346266407310067, 0.16328703751484963, 0.16343479506758796, 0.16347214799165388, 0.163658375543595, 0.16341578701326137, 0.16313811993859811, 0.16335844381362705, 0.16328199812999825, 0.16367789589781787, 0.16303974487078324, 0.16348132000861437, 0.16303866741855627, 0.1631170047895183, 0.16305870192683442, 0.1634072245382659, 0.16333304433307475, 0.16322071064563798, 0.162922338170996, 0.16315798664660172, 0.16302355582367378, 0.1626507379868645, 0.1627929135628389, 0.16283941333805332, 0.16280879855569957, 0.16273904547336807, 0.16243248614896108, 0.1623115949602602, 0.16220048621415967, 0.16259686309287508, 0.16242873478914288, 0.16234234105401918, 0.16247507484291834, 0.1626157131719664, 0.16240969802206273, 0.16224982064564844, 0.16224481083830544, 0.16207318990004768, 0.16259621184346246, 0.16236470351008875, 0.1625652094995907, 0.16233401392477392, 0.16229222498211443, 0.16258660124556265, 0.16232302056722728, 0.16220821627972953, 0.16273586887723523, 0.1622489055781272, 0.16211478856659797, 0.16204682066986548, 0.16158655846868603, 0.16180468262337047, 0.16186300427471695, 0.16160427413191358, 0.16151530834551894, 0.16158253425924654, 0.1618363479181119, 0.16138936334936993, 0.16170787999477546, 0.16182399729838676, 0.1618202534520303, 0.1614987745539408, 0.1617904199862268, 0.16147433673973105, 0.16145202910043596, 0.1617558233117726, 0.1617359079515723, 0.16124856665889628, 0.16162256491385454, 0.16103886512264445, 0.16094017034818472, 0.16134434948002074, 0.16165180481618063, 0.16109372552216333, 0.16108394276905258, 0.16070086364362707, 0.16089152342793797, 0.16107221940708033, 0.1606244279864798, 0.16113028438094484, 0.16128825738918115, 0.16071077546111606, 0.16104605455396423, 0.1612244825683597, 0.16123511479116195, 0.16102402851200326, 0.16110212548001315, 0.16057688527466407, 0.16044137254663396, 0.16070851002497014, 0.16127816061989064, 0.16125557374213895, 0.16080936456520817, 0.16060553010547834, 0.1611179166163703, 0.1608299674967493, 0.1608278127525588, 0.16082669253113896, 0.16064495758080252, 0.16060601493967097, 0.1603397521419124, 0.16104073109771186, 0.16042081453003515, 0.1605048204133416, 0.16023274469419238, 0.1607659771883761, 0.16060240786313673, 0.16057958512267395, 0.1603197976228984, 0.16052672463505446, 0.16013970052375048, 0.16012120490287307, 0.16034325940715463, 0.15991513245878924, 0.16036088438464632, 0.16084757227770857, 0.16027634821966288, 0.16085821539286013, 0.16042792411343423, 0.16008015376190082, 0.16083323439799233, 0.1602644803957797, 0.15990010067510038, 0.16032855951235803, 0.15991119395578957, 0.1598307191446369, 0.15963408179329083, 0.16014593980988837, 0.15982609663504502, 0.1601681981781918, 0.15978202237800823, 0.16012368545818742, 0.1599915546181934, 0.15997768650178512, 0.159563204454017, 0.15971014335883973, 0.1600816067603395, 0.15946775410830444, 0.15980428197054627, 0.1598902396499928, 0.1597071466239183, 0.1595261810671999, 0.1592833617296877, 0.1591784575982877, 0.15959843145014949, 0.1600374146807371, 0.15972669225302133, 0.15962535772711625, 0.15940550089759442, 0.15991629232426488, 0.1594549718412597, 0.15947357346638685, 0.15977109215535384, 0.1598096258659521, 0.15964002638723596, 0.1593580395127974, 0.15913152708613906, 0.15974773872921666, 0.1590558438881062, 0.15974689051603502, 0.1590088953941769, 0.15941937934542996, 0.1594731973147355, 0.15948922371114643, 0.15901425161094768, 0.15941146372707066, 0.15899729679395463, 0.1592105333243628, 0.1585312932974568, 0.15936286855299536, 0.1590703385466466, 0.1588790240038215, 0.15940113867141195, 0.15923862155579463, 0.15914988934668764, 0.15912481856756583, 0.1591353471533429, 0.15918596089887907, 0.15930332735473557, 0.15882235254840024, 0.15931096165622177, 0.1592011593098031, 0.15840275966054482, 0.1584764110653829, 0.15886711050040586, 0.15887652838485664, 0.159185073690486, 0.15886934998945548, 0.15905454354393392, 0.15874138851194797, 0.15869790544003456, 0.15947951267926436, 0.15885892669787213, 0.15858515705981474, 0.15826994611609907, 0.15879070183763191, 0.15870124849312264, 0.15896416872915636, 0.15864205861347144, 0.158773204566731, 0.15838582391712716, 0.1585778146180876, 0.15879247308587627, 0.15879183205993566, 0.15875168919420837, 0.15869345248137268, 0.1584726207582097, 0.15845417421355937, 0.15855967798397924, 0.15887045258300977, 0.15806961424280935, 0.15851535268984326, 0.15868183769342994, 0.1581495310845497, 0.15853376551684634, 0.1585566210144887, 0.15856350513393683, 0.15813880233084776, 0.15862820156191826, 0.15854693160259, 0.1578455347275928, 0.1583255017896204, 0.15830366164323453, 0.1585327307559064, 0.15880046123345906, 0.1581963329185105, 0.15835722159952942, 0.1585183585920561, 0.15843951384039506, 0.15855214915587018, 0.1584779944937779, 0.1581974032980002, 0.1584247206233064, 0.1576009303068721, 0.1577949201440124, 0.15831318409179002, 0.15851740246370577, 0.15825041511882562, 0.15864788756955328, 0.1581272052364341, 0.15811536758993425, 0.15790602335991127, 0.15783278619043767, 0.15800366032331908, 0.15809470651114402, 0.15834178952896014, 0.1579947574632431, 0.1579005133369806, 0.15807344009730412, 0.15853542575483423, 0.15819581698931504, 0.15776068212689684, 0.15783296493870852, 0.15822442724217897, 0.15795196903429481, 0.15825268393385908, 0.1583371385214122, 0.15787489745515235, 0.1577854498756752, 0.15798194228320706, 0.1582755020522797, 0.15802884086731683, 0.1581672855560147, 0.15796763669100947, 0.15799355942168028, 0.15806926363982152, 0.15793853310832112, 0.15815540399844497, 0.15777939682901107, 0.15821441174759895, 0.15782706215014974, 0.15765519096164174, 0.15765370264514725, 0.15779009763733198, 0.1577775124280997, 0.15740457451056844, 0.15768447060707536, 0.15743373372692962, 0.15722792150281759, 0.15701590445365923, 0.1572524995720229, 0.157490996091465, 0.15759489250192898, 0.15724761905943682, 0.15802434924732572, 0.15751635281506676, 0.15755538876457864, 0.157433705539484, 0.15781504159186843, 0.15786363754055036, 0.15744517068032574, 0.1572157194628834, 0.15765011606953463, 0.1579810137101521, 0.1573839565432003, 0.15747283082028304, 0.15781557746161998, 0.15748074402801307, 0.1578843077170732, 0.15734906883812777, 0.1574777002613364, 0.15764140228693085, 0.1574119742286687, 0.15754327595799292, 0.15750877334927504, 0.15745820517642903, 0.1572380587074646, 0.1573779397528009, 0.1569390062394941, 0.15708665108474162, 0.15704347339147628, 0.15724254660244366, 0.15694315663524752, 0.15701203502865438, 0.15688732504817954, 0.15692247028547243, 0.1576011816177547, 0.1572750212542729, 0.15720649203928994, 0.15726197065614553, 0.15694833994668542, 0.15699474370851751, 0.15690559086463782, 0.1571812823707506, 0.15715474629742276, 0.15689695309698737, 0.15749810579172285, 0.15689265796665258, 0.15711291572076977, 0.15664580650391113, 0.156936443441211, 0.15652412931039786, 0.1566051433946743, 0.15699958653137142, 0.15716091582110736, 0.157179826655624, 0.15686933179197804, 0.15695296088814406, 0.1569108017425005, 0.1565995196971075, 0.15655801376744252, 0.15652804393414485, 0.156570054694762, 0.15699530096008313, 0.15669554575361783, 0.1569818490756547, 0.15725271335454968, 0.15646153087331588, 0.1563219627723976, 0.15673572641814545, 0.1568230421666524, 0.1567121103792143, 0.1567517027878781, 0.15677551556576427, 0.15688381731661522, 0.1561974879328919, 0.15646724496391518, 0.15682868872958308, 0.156759395833706, 0.1567032097060665, 0.1567807957597911, 0.15685699715741816, 0.15691137347119696, 0.15682462344818507, 0.1569887042575353, 0.15704178680350758, 0.15679243701123455, 0.15661940118384882, 0.15649486738075213, 0.15669263212085527, 0.15642934448310888, 0.15623745901457395, 0.15635106116655703, 0.15673016390448608, 0.15646155835404427, 0.15642580486913624, 0.15666870219261958, 0.15648320884089, 0.1565283022749165, 0.1570843958798583, 0.1569907265885094, 0.1568883979952231, 0.1569219370856653, 0.15648090724085345, 0.15657836902519082, 0.15661353888518068, 0.15657687764254505, 0.1561936066917971, 0.15631226810408064, 0.15622275799069912, 0.15619371963077952, 0.15613555492965, 0.15663606426016746, 0.1559137356976646, 0.15643318379082916, 0.15689646800626195, 0.15687452663793192, 0.1564265591089556, 0.15652583721229124, 0.1566982564205229, 0.15605661768984586, 0.15626854903089502, 0.15654053577378507, 0.15567736867201748, 0.15631006990178703, 0.15632576292575595, 0.15638837194912855, 0.15640569151680983, 0.15623953767536522, 0.1562928979823655, 0.15615647568140173, 0.15603012859652152, 0.15606881281674972, 0.1562543214268944, 0.15613118808031243, 0.15577475213538863, 0.15619814646427463, 0.15647503903914856, 0.1566227729797399, 0.15581872784821624, 0.15621873987349627, 0.15611492908934035, 0.1560830439042543, 0.15601061598280028, 0.15616020588755866, 0.1561788213732476, 0.15591819755539918, 0.15567540628847384, 0.1561694817786007, 0.15586109677536528, 0.1561014747058039, 0.15592089393326036, 0.15604169904324283, 0.15581784314171357, 0.15646286561291625, 0.15610660559829778, 0.15620548036084414, 0.1560489604801476, 0.15594634506093244, 0.15575406209844142, 0.15588213994612712, 0.1560751201558642, 0.15630812195753427, 0.15610522819078212, 0.15606732008522, 0.15572940562591228, 0.1561111420152595, 0.15607791453036782, 0.15592458685034374, 0.1560354252598428, 0.15627589272690617, 0.15602488271667814, 0.15610110471149619, 0.1557940917725488, 0.15624784306888131, 0.15618381175310014, 0.15616055269875798, 0.15557093875030129, 0.15543170809407456, 0.1557346156290037, 0.15621862269198444, 0.15589515903022952, 0.15573651112036777, 0.15580172852695598, 0.15581931009753983, 0.1559752631364619, 0.1557706169780174, 0.15582314350890103, 0.1561050287963509, 0.15617490418751145, 0.1558475489543474, 0.15567533816315612, 0.15618280185525238, 0.15549484393787896, 0.1557352011893255, 0.15544872849109023, 0.1556611171917248, 0.15553211634848577, 0.15547379732367902, 0.15592536814908697, 0.15606297686917528, 0.15577059599574894, 0.15532585124103526, 0.15538707827269002, 0.1557438059271259, 0.15559887740586031, 0.15554722599238346, 0.15553374538963677, 0.15591486727330406, 0.1556364667530029, 0.15583782017885398, 0.15570816817801994, 0.15570155993873022, 0.15548994460324211, 0.15546161447417897, 0.15523376269144282, 0.15545593518300518, 0.1553188397099256, 0.1553974145189661, 0.15583376898728346, 0.1554800621896428, 0.15581448529319364, 0.15569430124355454, 0.1556634337858531, 0.15545803333639396, 0.15572025568412784, 0.15589495241058818, 0.15554745508452064, 0.15497914429753185, 0.15512536872233684, 0.15574929691654704, 0.15538154388303868, 0.1558813422559953, 0.15563371848094917, 0.1555168901674688, 0.15602098125679212, 0.15541713059269044, 0.1552555193550441, 0.15560936619622168, 0.1553359932725055, 0.15552780369490182, 0.15580820343374038, 0.15578736007921423, 0.15526638009904506, 0.1555729887489778, 0.15545714203015373, 0.15522034565429635, 0.15534213546125694, 0.15554247150696082, 0.15561620115263342, 0.15571472211582665, 0.1552573720549565, 0.15515364091839193, 0.15550956465134175, 0.15575050998280746, 0.1555976978958708, 0.15522845341294025, 0.1551932656112356, 0.15564220474177493, 0.1554496772940658, 0.15530760033018995, 0.15512093758621354, 0.15559972976474554, 0.15597288997100833, 0.1559083914105037, 0.1552245091705061, 0.15492080807445457, 0.15567232491887437, 0.15487603199264718, 0.15539561340941352, 0.1551453860913303, 0.15547182319638655, 0.15580757933006106, 0.15584075149735502, 0.15626917989791414, 0.15591323036922797, 0.15517948005275825, 0.15592953742031235, 0.15535058429055273, 0.15546667000000736, 0.15549537550945405, 0.15502081875533447, 0.15522327427948124, 0.1557796665826454, 0.15563316542405653, 0.15513697993328862, 0.15496125113030101, 0.15531357943753485, 0.15515042126258874, 0.15521629491791855, 0.1550686846483955, 0.15527951855937808, 0.1550049661412536, 0.15518479185095824, 0.1549892229793123, 0.15488042011361774, 0.15483469033300926, 0.1548178233069937, 0.15520953343116514, 0.1546421971482883, 0.15518980917065003, 0.15496674946179106, 0.1553934968680208, 0.15512058149308994, 0.15512282667037877, 0.1552564057187153, 0.15513244274172028, 0.15517477588115258, 0.1547207665629059, 0.15484106203236353, 0.15502589381660853, 0.15542447634318987, 0.1553432644960531, 0.15553692009043182, 0.1553222223859236, 0.1547731679336068, 0.1549573033609582, 0.1551526639435519, 0.15485056726038968, 0.15516939977613395, 0.1555021818822133, 0.15527372804036801, 0.15549080847215863, 0.15576713764535738, 0.155798997841589, 0.1554386966440745, 0.15558887484810138, 0.15532907499357268, 0.15484452310834654, 0.15520421148962485, 0.15508927962908922, 0.1549324567297351, 0.15427165150206124, 0.15501140166886207, 0.15500178885064583, 0.15479135832497018, 0.15463718882115626, 0.15464852069738208, 0.15492097818408077, 0.15540016176711455, 0.15525942275033378, 0.1556692640774636, 0.15519396373659175, 0.15547993313528102, 0.1548963802956299, 0.1550994993816507, 0.15488362406360373, 0.15535330870116085, 0.15501192009215733, 0.15498752822347286, 0.15585919074890586, 0.15540931516012768, 0.1557727952620137, 0.15535659229539936, 0.15519995484143592, 0.15501345356176338, 0.15476451728033053, 0.15532114316968584, 0.15475811435965464, 0.15505683242460017, 0.1548945670305405, 0.15460682110159096, 0.15471573974649228, 0.1543661070068989, 0.15457638822046865, 0.1542163771810271, 0.15459263466025353, 0.1546139389229761, 0.1546376212052425, 0.15485488425221594, 0.15493323098745987, 0.15483356274058405, 0.15456159970110211, 0.1552282666381421, 0.1551024397639397, 0.15483037286929618, 0.15471112908303974, 0.15469362138499868, 0.15515097474351172, 0.15461125642682255, 0.15492379834430428, 0.1549702083163447, 0.15512505049145117, 0.1548638038731768, 0.1552384413900649, 0.15480520675457282, 0.15472291082987394, 0.15488477338174164, 0.15485169200479998, 0.15530429044718239, 0.15552059677093877, 0.15532912401526563, 0.15462157048774144, 0.15444264611075853, 0.1543036338713431, 0.15468754882848648, 0.15455507682880532, 0.15425623722741152, 0.1548409807042319, 0.15441585132994515, 0.15458343467231433, 0.15454510452633557, 0.15438488798684952, 0.1547735979927602, 0.1542698668974172, 0.1551135918279235, 0.15460951675270196, 0.15488655795522335, 0.15498019476317604, 0.15455452636172537, 0.1540764350319151, 0.1540860100491051, 0.15427234442775908, 0.15449963737966696, 0.15442117073175504, 0.15474008702632605, 0.15434369744116824, 0.1549998633900183, 0.15418181840331197, 0.15456431884861427, 0.1550124484039295, 0.15502528072770194, 0.15454079861717143, 0.15486350342262956, 0.15426521205356314, 0.15443755625182676, 0.1544735465649218, 0.1547270379406849, 0.15432329006107456, 0.15445864102208096, 0.15483444349280892, 0.15435590779365546, 0.15446768222512067, 0.1543183540939991, 0.15429169203246074, 0.1544955949057599, 0.15457290076556846, 0.15424165597541772, 0.15460176812662235, 0.15424810107208917, 0.1546808377623923, 0.15422664392193916, 0.15437518484237722, 0.15458507478833688, 0.15430239505608984, 0.15525017685415285, 0.1545816738612266, 0.15422331946052317, 0.1543273967933874, 0.1544346080644856, 0.15411357236937756, 0.15425179363080568, 0.1547308553368314, 0.15441914472919002, 0.1547203059501952, 0.15422698115405906, 0.15428726646104024, 0.1539947513380456, 0.15416844234797586, 0.1542163192469061]
# ae_test_loss_history = [0.21952707878487118, 0.2036673321525931, 0.20009033804617976, 0.19852938388871347, 0.1934578959884394, 0.19173637342172997, 0.1898320993638305, 0.18578310161656494, 0.1844326195928665, 0.18269493200121104, 0.18194183502630762, 0.1814652326480603, 0.179975524201943, 0.18013164861738926, 0.17940708717976145, 0.17723886345885742, 0.17770977942011143, 0.1786085556473492, 0.17591858967521593, 0.17638576044809373, 0.17853429942901347, 0.17463601555395236, 0.17498774373020298, 0.174413950153736, 0.1735482853583605, 0.17353883379147805, 0.17362912887263376, 0.17343456849860373, 0.17231704502682374, 0.1719603779650575, 0.1739209915967842, 0.17099913356273364, 0.17109124105222115, 0.17046216746691412, 0.17084987392567186, 0.17078068873847926, 0.17010754800465167, 0.1697349215315946, 0.16947240171176883, 0.16861401266333922, 0.16899296160577423, 0.16768139368825632, 0.1695111231517612, 0.16845724249826285, 0.16820978830996647, 0.1672202929264, 0.16755609013705833, 0.16674794739740975, 0.16722676075151668, 0.16658807605356973, 0.16770877457890562, 0.1658351110223027, 0.166555857579593, 0.16531827386841888, 0.16491255001997038, 0.1661194515324426, 0.16499712971815397, 0.16635023271805133, 0.16460859680724219, 0.16424938714852802, 0.16554954772718217, 0.1639780311582425, 0.16393924854831293, 0.16587620134628123, 0.16420741079000867, 0.16425283272000896, 0.16360925002222995, 0.16431636457947782, 0.16391327429968042, 0.16377868478431024, 0.16327996316556725, 0.16293731589906535, 0.166761051051433, 0.1628098367889056, 0.1625710318162784, 0.16294855069184197, 0.16237888294025027, 0.1629945929016658, 0.16373456055965144, 0.1622455949196427, 0.16346075170546456, 0.16064468947585922, 0.16162298137194153, 0.16248675666680198, 0.16132739546476688, 0.16067529179011428, 0.1617364532804021, 0.16262110638638055, 0.1620843978682529, 0.160824359084285, 0.15977653317839835, 0.16143408708780455, 0.16086612097881983, 0.1619592650313103, 0.16165853681069847, 0.16200756803257887, 0.1598222691634891, 0.15976528762722705, 0.16035755314140174, 0.15970270580178197, 0.1600189034309312, 0.16187559058186882, 0.16226879815047635, 0.16081041552927974, 0.15982548541767896, 0.15980020429423064, 0.1589021237501754, 0.16038446647146248, 0.1593775540098385, 0.16187785476988134, 0.15864677217959858, 0.15914933636426756, 0.15829826032542466, 0.15922829068240363, 0.1589322004010543, 0.16095627515917152, 0.1586125632657237, 0.1581817164028317, 0.15894081719686268, 0.1573874950514661, 0.15859187101938535, 0.15749329140457055, 0.15728342733767262, 0.15883405233282874, 0.15898806546479513, 0.15967946460940688, 0.15993173412305067, 0.15916858167941944, 0.15788981884327313, 0.15771474643254674, 0.15724736929425043, 0.15851730269297595, 0.15745574565556822, 0.1605981951085255, 0.15768570324360887, 0.15870128277124562, 0.15952379522386287, 0.15685503200097742, 0.1579047013689732, 0.15758026164097266, 0.15908245856281872, 0.156895541910844, 0.1585798488600241, 0.1566206348267764, 0.1558914154505346, 0.15843256928340793, 0.15688508908041446, 0.15699934447422434, 0.15786825254275172, 0.15715894048351245, 0.15698058212663485, 0.15864577881763442, 0.15728504828731163, 0.15605428051773154, 0.15691396220669931, 0.15657912714786557, 0.15670689882303604, 0.15626892049387645, 0.15852083253984672, 0.15717579101139742, 0.15625052786969842, 0.15599487628937303, 0.15571750843425664, 0.15640085253997657, 0.15591396197079588, 0.15590320878506259, 0.1552498563119716, 0.1556291998277399, 0.15504424034917036, 0.15686344313082431, 0.15452275606959923, 0.15508646254819228, 0.15505530564965472, 0.1540464447823279, 0.15556825362161203, 0.1587066163018765, 0.15510342064666902, 0.1558186617593679, 0.1541692482821504, 0.15547695995120553, 0.15522212207310676, 0.15547241680756718, 0.1569383761536804, 0.15394530224120798, 0.15431170467301353, 0.1538230070641258, 0.15367385122325886, 0.15366692604172455, 0.15432516068421573, 0.15593368783740638, 0.15678289207639284, 0.15392250822166817, 0.15490638660754236, 0.15386854887671955, 0.15319623414710415, 0.15370610098305237, 0.15336856324453949, 0.15609007508064554, 0.15361895687788266, 0.15374912473645183, 0.15489224280806313, 0.153154238519295, 0.15201546968759017, 0.15377173773796085, 0.15539127355787494, 0.1535795468572292, 0.15309657153518255, 0.15403299739887522, 0.15463079937302357, 0.15492337508259738, 0.15312772652398543, 0.1553104607217756, 0.15301231291837727, 0.15622243893879248, 0.15214540621730335, 0.15267456454592176, 0.15361207022658116, 0.15347045826341676, 0.15772495950057164, 0.152233817643446, 0.15122239091457407, 0.15194807858095216, 0.15456184456037608, 0.15252684866059035, 0.15176085093540984, 0.15345726741820828, 0.15300895963126387, 0.1523133084445623, 0.1535698566836877, 0.1539739131929716, 0.15137869813814916, 0.15344197795709283, 0.15310283596242594, 0.15183995836229552, 0.15527920653805882, 0.15527488269283826, 0.1536937272483237, 0.15302862294404723, 0.15219923697957055, 0.1508778273968038, 0.15076759553575736, 0.15497740453795733, 0.15239459507070238, 0.15323524758007712, 0.1547200200481275, 0.15302430013215337, 0.1517940319946853, 0.15207097543742037, 0.1509700974068278, 0.15248177039992297, 0.15646378137400804, 0.15426804453502907, 0.15142149515061878, 0.15121852191840968, 0.1518245215845133, 0.1510431843828668, 0.15506649709612808, 0.1520374272500139, 0.15429937434245886, 0.15211539685786263, 0.1526024903035234, 0.1516532954373198, 0.15104077247698744, 0.15146269478743246, 0.15037501552310703, 0.15344977529921255, 0.15209993211459782, 0.15082084547047067, 0.1529173865258291, 0.15287010517697378, 0.15174075093886427, 0.1506544442724187, 0.14945192466121288, 0.150925462414946, 0.1510337598549785, 0.15176999877045297, 0.14964080116623185, 0.1507897271244239, 0.15116546874312708, 0.15003021638402927, 0.1493436507489782, 0.15086793274587698, 0.1515634330952558, 0.1509067469270819, 0.15050991699686594, 0.1517510786889056, 0.15135221095770512, 0.15067495201457012, 0.15113550337880974, 0.1515388102677045, 0.14943633526157435, 0.15206704273502192, 0.1513888583111974, 0.1538953186005188, 0.15069524173034735, 0.14957384256163805, 0.15122178260119706, 0.15377037991437167, 0.15263277344613485, 0.15114301692667578, 0.15345787806143935, 0.1513795126667033, 0.15159680850008408, 0.15024252414064565, 0.15220480259916747, 0.1517358744730715, 0.1504421062922477, 0.1506176414191133, 0.15062061640514618, 0.15006743561458524, 0.14884515516057908, 0.15014646312419355, 0.15043440625422647, 0.15055910335114522, 0.15097660141618618, 0.1530802701528427, 0.15021541885442627, 0.1487996680085763, 0.14841966160508968, 0.14977365837250659, 0.15077108044877446, 0.14909327170574094, 0.15083130208698264, 0.1497843274915186, 0.15014161965808198, 0.14975048765779952, 0.15030292724705227, 0.14854490720429794, 0.1498281114723476, 0.15138839596787937, 0.14932671291361005, 0.14913383644647205, 0.14848347639353326, 0.14955841983754442, 0.1503608863855157, 0.14910627598567355, 0.14882125687145564, 0.14886241911041126, 0.14907251842857774, 0.15223704706545688, 0.14784046420617797, 0.14955216820752668, 0.1482705692851591, 0.1502877119456312, 0.1497111069036076, 0.14835629361332156, 0.1518100446448386, 0.15084356629631243, 0.1504402231202328, 0.1502818075712634, 0.14882346629927276, 0.1488567546559233, 0.1508394261662334, 0.14821648021068667, 0.14894265053802344, 0.1501146549660629, 0.15147711518070883, 0.14988619277262163, 0.14937633679522896, 0.14752261652786303, 0.1509023476467847, 0.14884164458744967, 0.1535296613241516, 0.148869194378329, 0.14893370414159487, 0.14827483177291897, 0.1493189547878254, 0.15013934559698594, 0.1489569547746922, 0.14924054824080416, 0.1497259945514253, 0.14987177192250023, 0.1494545181376774, 0.14933583740170148, 0.14850474884865367, 0.14751476883819245, 0.15014209984506618, 0.1492427642731204, 0.1463593567482516, 0.1502321686694031, 0.1510825206589372, 0.148222686579102, 0.14786070994352526, 0.1501582495732154, 0.15342858364556777, 0.1466498558923428, 0.1521121032215793, 0.15051830187620766, 0.1484389620182018, 0.1480006674510004, 0.14722032903948296, 0.14643455010823261, 0.14918317207834614, 0.15003948084476695, 0.14989488588492267, 0.15027196748354885, 0.1499941076858961, 0.15195900472454524, 0.1487032184618325, 0.14977983599084554, 0.14770077063494316, 0.14960621950686825, 0.14883624397961365, 0.15039891815142367, 0.1478183731810107, 0.14895675225823493, 0.14923141701188347, 0.14906828996102747, 0.15011862279656193, 0.14917139899969287, 0.1508525304507139, 0.15010988520001844, 0.14933268339584796, 0.15022483528541786, 0.1474803097512992, 0.14838514922313256, 0.1478291373955731, 0.14859196526276672, 0.1504421667315667, 0.14726899098462326, 0.14762192815481012, 0.14937761302996644, 0.1540106284104886, 0.1483485948284246, 0.1474483475217613, 0.14807407197218114, 0.152369930139956, 0.14871001579297294, 0.14802070080604077, 0.14753436566416359, 0.15040770221205696, 0.14818816446428662, 0.14624325665311955, 0.14750537171377273, 0.15107938194264664, 0.15010238189583128, 0.14874983709880754, 0.1494055405587994, 0.1492410095936421, 0.14704601736144224, 0.14904780276633034, 0.15109097839588145, 0.14728747027024663, 0.14877016427587805, 0.1479654537506966, 0.1483277173244667, 0.14755534007491505, 0.15020662518502298, 0.14939222039528327, 0.1475556074511262, 0.14844834033796708, 0.14815004338712082, 0.14904905586501047, 0.15089022393538948, 0.14925252890071802, 0.1497162286968565, 0.14812390690062818, 0.14982922475919538, 0.14801005918898893, 0.1477981771295958, 0.14621069079439655, 0.14711640487241087, 0.14770397920122674, 0.14733704477865775, 0.14718791759827882, 0.1470570230222255, 0.14864048633103036, 0.14997898887393143, 0.147495245914836, 0.14578039367356352, 0.14848156233968396, 0.14972648330272376, 0.1506383943423746, 0.14694397756108213, 0.14852795271272687, 0.14916216070321076, 0.15015394882120559, 0.14998191260540075, 0.1490134687192045, 0.14784851803089694, 0.14690205798712147, 0.1499474154000473, 0.1474471048181143, 0.147686890669874, 0.14639042866415197, 0.14804609230681215, 0.14695368193688424, 0.14648731702474665, 0.1483253233106646, 0.14851122079038376, 0.14713306984219354, 0.14801547614698063, 0.14711281268483312, 0.1454537610320542, 0.14596205443191698, 0.14810199042866143, 0.15001302290518773, 0.14845087289489667, 0.1495796895426914, 0.14882155971408864, 0.14945505362795175, 0.14971724359619862, 0.14567286471755828, 0.14766187980615816, 0.14714577171686244, 0.14701600034024834, 0.14886942763472605, 0.14621829720589405, 0.14849323129773234, 0.14672058953827208, 0.14716647048033737, 0.15017974619123514, 0.14658969751075748, 0.1476617802317457, 0.14749683890622628, 0.1478773536580499, 0.14524535309723527, 0.14833346946649284, 0.14805590518414607, 0.14557990588203537, 0.14558563320752668, 0.14780318084370409, 0.14754249228917082, 0.14504190267118383, 0.14727579633865262, 0.14690558391658776, 0.14844191391102393, 0.14870742468308812, 0.14704009723510195, 0.14570142654874219, 0.1455565161910948, 0.15093303589743137, 0.14919414797464556, 0.1497286917100125, 0.14611797733529733, 0.14753761458639078, 0.14673322221788906, 0.14571648279241203, 0.1465867800376757, 0.14578123607411672, 0.14713841322921442, 0.1479704441083475, 0.14644984688610255, 0.1470547236621529, 0.14760107701598604, 0.14659228847652186, 0.1459594886538393, 0.1481380049249021, 0.14704248542955517, 0.15240944930150174, 0.14739217585768397, 0.1472484769534796, 0.147734379985053, 0.1484801845901946, 0.14719532479529038, 0.14639476793025757, 0.14765485520045277, 0.1456236354242968, 0.14843564169849557, 0.14702397867814088, 0.14923503399039942, 0.14760748724913578, 0.14716234952550813, 0.1491605582505096, 0.14799206315694297, 0.14806283621563399, 0.1454007057711989, 0.14627308016287843, 0.1470660515255602, 0.1473653050570586, 0.14747907063118698, 0.1475424174478258, 0.14821425738467847, 0.14763412861505926, 0.14587970351486415, 0.14786882054835135, 0.1451103009998302, 0.14535976788489188, 0.14501977548681508, 0.14711558205999303, 0.14723076018952705, 0.1449774341658662, 0.1511611411162757, 0.14691656848292686, 0.14599202568625233, 0.14661077257265115, 0.14825641877990695, 0.14622606985612357, 0.14541362134028266, 0.14512234623626516, 0.1451260352972495, 0.14690631554974679, 0.14772045626691602, 0.14615753720056762, 0.1472155554573078, 0.14559938355547483, 0.14616927087202364, 0.14666119688851478, 0.14847265207741667, 0.14910702735331413, 0.14883319058205577, 0.1460885003744975, 0.14743869151366273, 0.1471482627081272, 0.1457390245249818, 0.1470965567577401, 0.1446453064631132, 0.1463923012463764, 0.1448975548077486, 0.14676920275123442, 0.1472165227690886, 0.14842890764011502, 0.14870989009603863, 0.1464196453234396, 0.14693284574206794, 0.1469959560559833, 0.1460221383577768, 0.14722533639388388, 0.14881872860308237, 0.1456755006945228, 0.14528174714656783, 0.1470037215652964, 0.14963253364876736, 0.14624159820601798, 0.14507318782687983, 0.14410059120757981, 0.14931828774454223, 0.14542613572040503, 0.14799671328801403, 0.14373058434853325, 0.14479049007419137, 0.146758627767341, 0.1472348569076418, 0.14785566597363428, 0.146182670937793, 0.14382367021980794, 0.14906837260435096, 0.14986741883919708, 0.14755661279956908, 0.1461482025058868, 0.1452104164481301, 0.14466145212695528, 0.1467697226158503, 0.14683751811548595, 0.14605429933215724, 0.147484544636938, 0.14702204621026468, 0.15214949753451923, 0.14441701309144253, 0.14720473749528806, 0.14659440568785825, 0.14436177037751738, 0.14413138043322232, 0.1463412785275014, 0.1487719250362365, 0.1450052713067115, 0.1468409671575424, 0.1458035658205716, 0.1451123257798964, 0.1498365057584681, 0.14647163906783936, 0.14626584957347893, 0.14592956810485186, 0.14455508981963563, 0.14570972406384283, 0.1453527355039176, 0.14618171782326478, 0.14523144016531542, 0.14353777323583272, 0.1438297835593263, 0.1453032307870723, 0.1441583863648268, 0.14552577598976624, 0.14534327930960111, 0.14442626841249714, 0.14349873350227407, 0.14960285281878152, 0.14778644873049882, 0.1459146767444031, 0.15044881442453306, 0.14520556485006553, 0.1469434551835403, 0.14566986964870646, 0.14480813854175792, 0.14744707713141292, 0.1449923971753092, 0.148429882519609, 0.14814614675266613, 0.15140630356507542, 0.14568874305638255, 0.14742712432688945, 0.14417825963657954, 0.14495884689676553, 0.1444092267280715, 0.14496108723034437, 0.1435025700029005, 0.14456135002342732, 0.1444626150812676, 0.1468335396618095, 0.1456993508524337, 0.14470771783583417, 0.14770773779947943, 0.1463571934857109, 0.1438511105114415, 0.14339070399211998, 0.14484187885392721, 0.14584040408632326, 0.14564033437811985, 0.14508019250891083, 0.14524972949020803, 0.14680383378770095, 0.14576475816763224, 0.14568555792051816, 0.14572209740349237, 0.14725989657207095, 0.14392207278243865, 0.14607341039607663, 0.14630471545385057, 0.14998106976747824, 0.14653775666189084, 0.1454203338234467, 0.14631328256205717, 0.14533315504423922, 0.14716449214655458, 0.1466804858031544, 0.1465869149661072, 0.1435454427815342, 0.14956601680998904, 0.1436529487072075, 0.14595105255499036, 0.14550388054324387, 0.14794681797311066, 0.14555065219214633, 0.14717984643125467, 0.14741281409058213, 0.1454766643277035, 0.14402990902822135, 0.14422733857106484, 0.14361879889717283, 0.1450763259227292, 0.14586575251679035, 0.14408511172062902, 0.143581117172501, 0.14498735985443328, 0.14578450069155854, 0.14573045180887712, 0.1437156811279198, 0.14373452189760685, 0.14755590928491624, 0.1471923976221809, 0.14557729883321108, 0.1435384783664149, 0.14373997848481915, 0.144579103583716, 0.14871668660752896, 0.14818908023938396, 0.1461742728995335, 0.14568562768036633, 0.14449138879228454, 0.1436770857365378, 0.145470824152584, 0.14849337367034526, 0.14629261582225106, 0.14423994268590312, 0.1459848136883871, 0.14422933470455426, 0.1441414096581223, 0.14409240518659638, 0.1437585583887542, 0.14798494753501845, 0.145341201940049, 0.14416225007750322, 0.1463056248542624, 0.14199901120317424, 0.14426472621106234, 0.14420902230177446, 0.14470405608483491, 0.1440720832496108, 0.14588168860616968, 0.14798429695039864, 0.14680966960192574, 0.14413963558916115, 0.14453247944568118, 0.14311168228116686, 0.14437877493730167, 0.14382183902128937, 0.14555071487840845, 0.14442910454100857, 0.14465523282665355, 0.14638532196682158, 0.14452420203843971, 0.14418627617806903, 0.14503068846592584, 0.14602593693915197, 0.14483737768327473, 0.14447910338111586, 0.1440233003490424, 0.1450819783384322, 0.14392382833053463, 0.14687321609045198, 0.14407081174914566, 0.14474516739864507, 0.14481615321079483, 0.1453313443414251, 0.14466692487679975, 0.14386842452336596, 0.14406293757414818, 0.14441105718150418, 0.14520005652863022, 0.14473200903895847, 0.14469227999412052, 0.1467112743977832, 0.14427448328986606, 0.1445009533751736, 0.14329399375880092, 0.14416301629845032, 0.14665798128926597, 0.1468092131514079, 0.14216956152686785, 0.1452216841560076, 0.14577951194705474, 0.14455824888528446, 0.14510646063744423, 0.14267267804442468, 0.1426923907560125, 0.1437313441185613, 0.14610036447493435, 0.14640585509308637, 0.14511254818497177, 0.14588126934651072, 0.14455663924269932, 0.1452776067544011, 0.14494229158815541, 0.14464464546454095, 0.1448264848787971, 0.14523852691363173, 0.14432462489265738, 0.14415939443875936, 0.1464246710601498, 0.1486023980009177, 0.14253982218642708, 0.1470582557248056, 0.14379148631080485, 0.14759771188651435, 0.14502692427146052, 0.14435694319033596, 0.14526220124796796, 0.14407352991982247, 0.14299591636400857, 0.1473460792065103, 0.1440283699834973, 0.1470674843763485, 0.14523859076231685, 0.1452844561920293, 0.14321104948629013, 0.14626570855804633, 0.14538926530244473, 0.14333796784503755, 0.14284996890245816, 0.14494219863270977, 0.1448552282338244, 0.14460299169426516, 0.14603473818127652, 0.1452095148841966, 0.14444513629351682, 0.14484969074775786, 0.14344084881731037, 0.14341498646176937, 0.14807154765626868, 0.14529328358505458, 0.1428492891838118, 0.14457482605234387, 0.14584925988164402, 0.14331123037750296, 0.14221018555562398, 0.1433552009197127, 0.14730007049939806, 0.1444524211300653, 0.14290964924940594, 0.14370145475522972, 0.14607550682847578, 0.14529443731298278, 0.1475720748846746, 0.14556206052983697, 0.14278991430983382, 0.14467542585877344, 0.14333900371696137, 0.14897251240329, 0.14531793592891326, 0.14424208002234865, 0.14432910649798894, 0.14398272432741055, 0.14466874046468403, 0.144891698567932, 0.14428908244699631, 0.14429612028340147, 0.1452130488265357, 0.14776405274151305, 0.1429678117862991, 0.1471472124019033, 0.14311522883153877, 0.14512752656076774, 0.1452078182674415, 0.1435263616022917, 0.1439119762516328, 0.14299320406220467, 0.14300333561260342, 0.14541070810011225, 0.14261539164339215, 0.14753142533269276, 0.142010343066897, 0.1495189728124427, 0.14545239011353894, 0.14524606082309793, 0.14469963598442317, 0.14533527984999842, 0.14249088547876496, 0.14386196494983894, 0.1461371196900415, 0.14268217094994057, 0.14339720068917547, 0.1434876124093805, 0.14311933726792356, 0.1427720053387639, 0.14573865087470622, 0.14391731062862337, 0.14724298710394193, 0.1464614820754565, 0.14445402527103424, 0.14531888206278246, 0.14993098159051643, 0.14329770946036158, 0.14345146793822178, 0.14513640744973522, 0.14244997404495433, 0.14624110151919317, 0.14571118077574222, 0.14579034914831598, 0.14395331506982154, 0.1433235748374234, 0.14316320466887955, 0.14411047238408195, 0.14285954424819347, 0.14530115425720247, 0.14275619386235525, 0.14387533061311789, 0.14169978263956495, 0.1440273393477633, 0.14403979606135447, 0.1433050229240111, 0.1446251153702198, 0.14409685972900643, 0.14491295235862323, 0.14433224754079488, 0.14382077105614055, 0.1438492320041428, 0.14632467962775025, 0.1440357544489903, 0.14353046701548636, 0.14528544520923575, 0.14906597638255722, 0.14442900469004072, 0.14427852937274555, 0.14506480782426157, 0.14384541511502258, 0.14549962212702502, 0.14575761319967392, 0.14471172596718831, 0.14285836871857382, 0.14503430558466707, 0.1453857151490623, 0.1439541931020621, 0.14449864441189553, 0.14249644903560355, 0.14640500721373137, 0.14560060303403255, 0.14349469819559563, 0.14352857939632707, 0.14414179825518797, 0.14380503339498402, 0.14435182310705638, 0.14355065064416614, 0.1450129049441702, 0.14428517077783254, 0.14636357367058758, 0.14504188658311584, 0.14360292020333373, 0.14760504426944693, 0.14344227238763388, 0.14521805801332485, 0.14751180792087232, 0.14803202415330394, 0.14586003872415093, 0.14261076704166775, 0.14645087953952246, 0.14475727975346242, 0.14402108828365467, 0.14259169920274561, 0.1429321644460119, 0.14532801414028865]
ae_train_loss_history = []
ae_test_loss_history = []


def autoencoder_objective(X):
    X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)

    X_train = torch.tensor(X_train, dtype=torch.float32)
    X_test = torch.tensor(X_test, dtype=torch.float32)

    train_dataset = TensorDataset(X_train, X_train)
    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_dataset = TensorDataset(X_test, X_test)
    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)

    torch.manual_seed(42)
    model = AutoEncoder()
    MSE = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)

    best_mse = float('inf')
    best_weights = None

    # train_loss_ma = None
    # test_loss_ma = None
    # convergence_threshold = 0.0001
    # consecutive_epochs_no_improvement = 0

    # Training
    num_epoch = 5000
    for epoch in range(num_epoch):
        model.train()
        train_mse = 0.0
        for X_train_batch in train_dataloader:
            optimizer.zero_grad()
            # Extract input from tuple
            X_train_batch = X_train_batch[0]
            # Get encoder output
            latent_space = model.encoder(X_train_batch)
            # Use latent space for reconstruction in the decoder
            predictions = model.decoder(latent_space)
            loss_value = MSE(predictions, X_train_batch)
            loss_value.backward()
            optimizer.step()
            train_mse += loss_value.item() * len(X_train_batch)

        train_mse /= len(X_train)
        ae_train_loss_history.append(train_mse)

        # Evaluating on the validation set
        model.eval()
        test_mse = 0.0
        with torch.no_grad():
            for X_test_batch in test_dataloader:
                # Extract input from tuple
                X_test_batch = X_test_batch[0]
                # Get encoder output for the test set
                latent_space = model.encoder(X_test_batch)
                # Use latent space for reconstruction in the decoder
                pred = model.decoder(latent_space)
                batch_mse = MSE(pred, X_test_batch).item()
                test_mse += batch_mse * len(X_test_batch)

        test_mse /= len(X_test)
        ae_test_loss_history.append(test_mse)

        # if train_loss_ma is None:
        #     train_loss_ma = train_mse
        # else:
        #     train_loss_ma = (train_loss_ma * epoch + train_mse) / (epoch + 1)
        #
        # if test_loss_ma is None:
        #     test_loss_ma = test_mse
        # else:
        #     test_loss_ma = (test_loss_ma * epoch + test_mse) / (epoch + 1)
        #
        # if epoch > 0:
        #     if abs(test_loss_ma - ae_test_loss_history[-2]) < convergence_threshold:
        #         consecutive_epochs_no_improvement += 1
        #         if consecutive_epochs_no_improvement >= 5:
        #             print(f"Model converges at {epoch}th epoch")
        #             break
        #     else:
        #         consecutive_epochs_no_improvement = 0

        if test_mse < best_mse:
            best_mse = test_mse
            best_weights = copy.deepcopy(model.state_dict())
            torch.save(model.state_dict(), "/home/fanqiany/data/fanqiany/AE1.pth")
            # torch.save(model.state_dict(), "/home/fanqiany/data/fanqiany/AE.pth")
            print(f"Epoch {epoch + 1}/{num_epoch}, Test MSE: {test_mse:.6f}")

    return best_mse


best_mse = autoencoder_objective(cleaned_df)
print("Best AutoEncoder MSE:", best_mse)

# Explained variance
cov_matrix = np.cov(cleaned_df.T)
explained_var = 1 - 19 * best_mse / np.trace(cov_matrix)
print("Explained Variance of AutoEncoder:", explained_var)

print("Train History:", ae_train_loss_history)
print("Test History:", ae_test_loss_history)


# Plot AE
def plot_ae(data):
    data = torch.tensor(data, dtype=torch.float32)
    model = AutoEncoder(input_size=19, latent_size=2)

    model.eval()
    with torch.no_grad():
        latent = model.encoder(data)

    plt.figure(figsize=(10, 8))
    plt.hist2d(latent[:, 0], latent[:, 1], bins=(50, 50), cmap='viridis')
    plt.colorbar(label='Frequency')
    plt.title('AutoEncoder of Chemical Abundances')
    plt.xlabel('Latent Component 1')
    plt.ylabel('Latent Component 2')
    plt.grid(True)
    plt.xlim(latent[:, 0].min(), latent[:, 0].max())
    plt.ylim(latent[:, 1].min(), latent[:, 1].max())
    plt.savefig("/home/fanqiany/data/fanqiany/AE.png", dpi=300, bbox_inches='tight')
    plt.close()


plot_ae(cleaned_df)
